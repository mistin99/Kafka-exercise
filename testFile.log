18:05:12 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

18:05:36 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
18:05:37 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
18:05:37 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684508464357
18:05:63 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
18:05:66 [main] INFO  producer.MessageProducer - Message ABd sent successfully for the key null
18:05:66 [main] INFO  producer.MessageProducer - Published message Offset is 9 and the partition is 0
18:05:31 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

18:05:54 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
18:05:55 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
18:05:55 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684509235539
18:05:59 [kafka-producer-network-thread | producer-1] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Connection to node -2 (localhost/127.0.0.1:9093) could not be established. Broker may not be available.
18:05:64 [kafka-producer-network-thread | producer-1] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
18:05:69 [kafka-producer-network-thread | producer-1] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
18:05:74 [kafka-producer-network-thread | producer-1] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Connection to node -2 (localhost/127.0.0.1:9093) could not be established. Broker may not be available.
18:05:77 [kafka-producer-network-thread | producer-1] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
09:05:87 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

09:05:12 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
09:05:13 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
09:05:13 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684737717120
09:05:16 [kafka-producer-network-thread | producer-1] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
09:05:17 [kafka-producer-network-thread | producer-1] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Connection to node -2 (localhost/127.0.0.1:9093) could not be established. Broker may not be available.
09:05:48 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
09:05:52 [main] INFO  producer.MessageProducer - Message ABd sent successfully for the key null
09:05:52 [main] INFO  producer.MessageProducer - Published message Offset is 11 and the partition is 0
09:05:55 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

09:05:79 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
09:05:79 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
09:05:79 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684737870784
09:05:81 [kafka-producer-network-thread | producer-1] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
09:05:07 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
09:05:10 [main] INFO  producer.MessageProducer - Message ABd sent successfully for the key null
09:05:10 [main] INFO  producer.MessageProducer - Published message Offset is 12 and the partition is 0
09:05:06 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

09:05:30 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
09:05:31 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
09:05:31 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684738376299
09:05:32 [kafka-producer-network-thread | producer-1] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
09:05:57 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
09:05:59 [main] INFO  producer.MessageProducer - Message ABd sent successfully for the key 1
09:05:59 [main] INFO  producer.MessageProducer - Published message Offset is 13 and the partition is 0
09:05:60 [main] INFO  producer.MessageProducer - Message ABc sent successfully for the key 1
09:05:60 [main] INFO  producer.MessageProducer - Published message Offset is 14 and the partition is 0
09:05:01 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

09:05:25 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
09:05:25 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
09:05:25 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684738550243
09:05:57 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
09:05:62 [main] INFO  producer.MessageProducer - Message Haha1 sent successfully for the key 1
09:05:62 [main] INFO  producer.MessageProducer - Published message Offset is 15 and the partition is 0
09:05:63 [main] INFO  producer.MessageProducer - Message Haha12 sent successfully for the key 1
09:05:63 [main] INFO  producer.MessageProducer - Published message Offset is 16 and the partition is 0
09:05:12 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

09:05:35 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
09:05:36 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
09:05:36 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684738612354
09:05:64 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
09:05:67 [main] INFO  producer.MessageProducer - Message Haha1 sent successfully for the key 9
09:05:67 [main] INFO  producer.MessageProducer - Published message Offset is 17 and the partition is 0
09:05:67 [main] INFO  producer.MessageProducer - Message Haha12 sent successfully for the key 9
09:05:67 [main] INFO  producer.MessageProducer - Published message Offset is 18 and the partition is 0
09:05:42 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

09:05:67 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
09:05:67 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
09:05:67 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684738650662
09:05:93 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
09:05:96 [main] INFO  producer.MessageProducer - Message Haha1 sent successfully for the key 99
09:05:96 [main] INFO  producer.MessageProducer - Published message Offset is 19 and the partition is 0
09:05:96 [main] INFO  producer.MessageProducer - Message Haha12 sent successfully for the key 9
09:05:96 [main] INFO  producer.MessageProducer - Published message Offset is 20 and the partition is 0
10:05:34 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

10:05:57 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
10:05:57 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
10:05:57 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684739313565
10:05:83 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
10:05:86 [main] INFO  producer.MessageProducer - Message Haha1 sent successfully for the key 99
10:05:86 [main] INFO  producer.MessageProducer - Published message Offset is 21 and the partition is 0
10:05:86 [main] INFO  producer.MessageProducer - Message Haha12 sent successfully for the key 9
10:05:86 [main] INFO  producer.MessageProducer - Published message Offset is 22 and the partition is 0
10:05:44 [main] INFO  producer.MessageProducer - Selected Option is : 1 
10:05:53 [main] INFO  producer.MessageProducer - Entered message is Hello mate
10:05:56 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

10:05:79 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
10:05:79 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
10:05:79 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684739337790
10:05:06 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
10:05:09 [main] INFO  producer.MessageProducer - Message Hello mate sent successfully for the key null
10:05:09 [main] INFO  producer.MessageProducer - Published message Offset is 23 and the partition is 0
10:05:09 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:05:61 [main] INFO  producer.MessageProducer - Entered message is 00
10:05:61 [main] INFO  producer.MessageProducer - Exiting from Option : 1
10:05:72 [main] INFO  producer.MessageProducer - Selected Option is : 123 
10:05:87 [main] INFO  producer.MessageProducer - Selected Option is : 2 
10:05:02 [main] INFO  producer.MessageProducer - Selected Option is : 1 
10:05:07 [main] INFO  producer.MessageProducer - Entered message is A-apple
10:05:10 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

10:05:33 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
10:05:33 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
10:05:33 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684739407327
10:05:60 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
10:05:63 [main] INFO  producer.MessageProducer - Message apple sent successfully for the key A
10:05:63 [main] INFO  producer.MessageProducer - Published message Offset is 24 and the partition is 0
10:05:63 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:05:65 [main] INFO  producer.MessageProducer - Entered message is 00
10:05:65 [main] INFO  producer.MessageProducer - Exiting from Option : 1
10:05:66 [main] INFO  producer.MessageProducer - Selected Option is : 2 
10:05:37 [main] INFO  producer.MessageProducer - Selected Option is : 1 
10:05:50 [main] INFO  producer.MessageProducer - Entered message is Welcome my child
10:05:53 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

10:05:76 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
10:05:76 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
10:05:76 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684741824764
10:05:04 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
10:05:13 [main] INFO  producer.MessageProducer - Message Welcome my child sent successfully for the key null
10:05:13 [main] INFO  producer.MessageProducer - Published message Offset is 0 and the partition is 0
10:05:13 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:05:68 [main] INFO  producer.MessageProducer - Selected Option is : 1 
10:05:68 [main] INFO  producer.MessageProducer - Entered message is ratatata
10:05:70 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

10:05:93 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
10:05:93 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
10:05:93 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684741964929
10:05:96 [kafka-producer-network-thread | producer-1] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
10:05:02 [kafka-producer-network-thread | producer-1] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
10:05:27 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
10:05:30 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 3 on topic-partition test-topic-replicated-2, retrying (2147483646 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:41 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 4 on topic-partition test-topic-replicated-2, retrying (2147483645 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:52 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 5 on topic-partition test-topic-replicated-2, retrying (2147483644 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:63 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 6 on topic-partition test-topic-replicated-2, retrying (2147483643 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:74 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 7 on topic-partition test-topic-replicated-2, retrying (2147483642 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:85 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 8 on topic-partition test-topic-replicated-2, retrying (2147483641 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:96 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 9 on topic-partition test-topic-replicated-2, retrying (2147483640 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:06 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 10 on topic-partition test-topic-replicated-2, retrying (2147483639 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:17 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 11 on topic-partition test-topic-replicated-2, retrying (2147483638 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:28 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 12 on topic-partition test-topic-replicated-2, retrying (2147483637 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:39 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 13 on topic-partition test-topic-replicated-2, retrying (2147483636 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:50 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 14 on topic-partition test-topic-replicated-2, retrying (2147483635 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:61 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 15 on topic-partition test-topic-replicated-2, retrying (2147483634 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:73 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 16 on topic-partition test-topic-replicated-2, retrying (2147483633 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:83 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 17 on topic-partition test-topic-replicated-2, retrying (2147483632 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:94 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 18 on topic-partition test-topic-replicated-2, retrying (2147483631 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:05 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 19 on topic-partition test-topic-replicated-2, retrying (2147483630 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:16 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 20 on topic-partition test-topic-replicated-2, retrying (2147483629 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:27 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 21 on topic-partition test-topic-replicated-2, retrying (2147483628 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:38 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 22 on topic-partition test-topic-replicated-2, retrying (2147483627 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:49 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 23 on topic-partition test-topic-replicated-2, retrying (2147483626 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:60 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 24 on topic-partition test-topic-replicated-2, retrying (2147483625 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:70 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 25 on topic-partition test-topic-replicated-2, retrying (2147483624 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:81 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 26 on topic-partition test-topic-replicated-2, retrying (2147483623 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:92 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 27 on topic-partition test-topic-replicated-2, retrying (2147483622 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:03 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 28 on topic-partition test-topic-replicated-2, retrying (2147483621 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:14 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 29 on topic-partition test-topic-replicated-2, retrying (2147483620 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:24 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 30 on topic-partition test-topic-replicated-2, retrying (2147483619 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:35 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 31 on topic-partition test-topic-replicated-2, retrying (2147483618 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:46 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 32 on topic-partition test-topic-replicated-2, retrying (2147483617 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:57 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 33 on topic-partition test-topic-replicated-2, retrying (2147483616 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:68 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 34 on topic-partition test-topic-replicated-2, retrying (2147483615 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:79 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 35 on topic-partition test-topic-replicated-2, retrying (2147483614 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:90 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 36 on topic-partition test-topic-replicated-2, retrying (2147483613 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:01 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 37 on topic-partition test-topic-replicated-2, retrying (2147483612 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:12 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 38 on topic-partition test-topic-replicated-2, retrying (2147483611 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:23 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 39 on topic-partition test-topic-replicated-2, retrying (2147483610 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:34 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 40 on topic-partition test-topic-replicated-2, retrying (2147483609 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:45 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 41 on topic-partition test-topic-replicated-2, retrying (2147483608 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:56 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 42 on topic-partition test-topic-replicated-2, retrying (2147483607 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:68 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 43 on topic-partition test-topic-replicated-2, retrying (2147483606 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:78 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 44 on topic-partition test-topic-replicated-2, retrying (2147483605 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:89 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 45 on topic-partition test-topic-replicated-2, retrying (2147483604 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:00 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 46 on topic-partition test-topic-replicated-2, retrying (2147483603 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:11 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 47 on topic-partition test-topic-replicated-2, retrying (2147483602 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:22 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 48 on topic-partition test-topic-replicated-2, retrying (2147483601 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:33 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 49 on topic-partition test-topic-replicated-2, retrying (2147483600 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:44 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 50 on topic-partition test-topic-replicated-2, retrying (2147483599 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:55 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 51 on topic-partition test-topic-replicated-2, retrying (2147483598 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:66 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 52 on topic-partition test-topic-replicated-2, retrying (2147483597 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:76 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 53 on topic-partition test-topic-replicated-2, retrying (2147483596 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:87 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 54 on topic-partition test-topic-replicated-2, retrying (2147483595 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:99 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 55 on topic-partition test-topic-replicated-2, retrying (2147483594 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:09 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 56 on topic-partition test-topic-replicated-2, retrying (2147483593 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:20 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 57 on topic-partition test-topic-replicated-2, retrying (2147483592 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:31 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 58 on topic-partition test-topic-replicated-2, retrying (2147483591 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:42 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 59 on topic-partition test-topic-replicated-2, retrying (2147483590 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:53 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 60 on topic-partition test-topic-replicated-2, retrying (2147483589 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:64 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 61 on topic-partition test-topic-replicated-2, retrying (2147483588 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:75 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 62 on topic-partition test-topic-replicated-2, retrying (2147483587 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:86 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 63 on topic-partition test-topic-replicated-2, retrying (2147483586 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:97 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 64 on topic-partition test-topic-replicated-2, retrying (2147483585 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:07 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 65 on topic-partition test-topic-replicated-2, retrying (2147483584 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:19 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 66 on topic-partition test-topic-replicated-2, retrying (2147483583 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:30 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 67 on topic-partition test-topic-replicated-2, retrying (2147483582 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:40 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 68 on topic-partition test-topic-replicated-2, retrying (2147483581 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:51 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 69 on topic-partition test-topic-replicated-2, retrying (2147483580 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:62 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 70 on topic-partition test-topic-replicated-2, retrying (2147483579 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:73 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 71 on topic-partition test-topic-replicated-2, retrying (2147483578 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:84 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 72 on topic-partition test-topic-replicated-2, retrying (2147483577 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:95 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 73 on topic-partition test-topic-replicated-2, retrying (2147483576 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:06 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 74 on topic-partition test-topic-replicated-2, retrying (2147483575 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:17 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 75 on topic-partition test-topic-replicated-2, retrying (2147483574 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:28 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 76 on topic-partition test-topic-replicated-2, retrying (2147483573 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:38 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 77 on topic-partition test-topic-replicated-2, retrying (2147483572 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:49 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 78 on topic-partition test-topic-replicated-2, retrying (2147483571 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:60 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 79 on topic-partition test-topic-replicated-2, retrying (2147483570 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:71 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 80 on topic-partition test-topic-replicated-2, retrying (2147483569 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:83 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 81 on topic-partition test-topic-replicated-2, retrying (2147483568 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:93 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 82 on topic-partition test-topic-replicated-2, retrying (2147483567 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:05 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 83 on topic-partition test-topic-replicated-2, retrying (2147483566 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:16 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 84 on topic-partition test-topic-replicated-2, retrying (2147483565 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:27 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 85 on topic-partition test-topic-replicated-2, retrying (2147483564 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:38 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 86 on topic-partition test-topic-replicated-2, retrying (2147483563 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:49 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 87 on topic-partition test-topic-replicated-2, retrying (2147483562 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:60 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 88 on topic-partition test-topic-replicated-2, retrying (2147483561 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:71 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 89 on topic-partition test-topic-replicated-2, retrying (2147483560 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:81 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 90 on topic-partition test-topic-replicated-2, retrying (2147483559 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:92 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 91 on topic-partition test-topic-replicated-2, retrying (2147483558 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:03 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 92 on topic-partition test-topic-replicated-2, retrying (2147483557 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:14 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 93 on topic-partition test-topic-replicated-2, retrying (2147483556 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:25 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 94 on topic-partition test-topic-replicated-2, retrying (2147483555 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:36 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 95 on topic-partition test-topic-replicated-2, retrying (2147483554 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:47 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 96 on topic-partition test-topic-replicated-2, retrying (2147483553 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:58 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 97 on topic-partition test-topic-replicated-2, retrying (2147483552 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:69 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 98 on topic-partition test-topic-replicated-2, retrying (2147483551 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:80 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 99 on topic-partition test-topic-replicated-2, retrying (2147483550 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:91 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 100 on topic-partition test-topic-replicated-2, retrying (2147483549 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:02 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 101 on topic-partition test-topic-replicated-2, retrying (2147483548 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:13 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 102 on topic-partition test-topic-replicated-2, retrying (2147483547 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:24 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 103 on topic-partition test-topic-replicated-2, retrying (2147483546 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:35 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 104 on topic-partition test-topic-replicated-2, retrying (2147483545 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:45 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 105 on topic-partition test-topic-replicated-2, retrying (2147483544 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:56 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 106 on topic-partition test-topic-replicated-2, retrying (2147483543 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:67 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 107 on topic-partition test-topic-replicated-2, retrying (2147483542 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:78 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 108 on topic-partition test-topic-replicated-2, retrying (2147483541 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:89 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 109 on topic-partition test-topic-replicated-2, retrying (2147483540 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:00 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 110 on topic-partition test-topic-replicated-2, retrying (2147483539 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:11 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 111 on topic-partition test-topic-replicated-2, retrying (2147483538 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:22 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 112 on topic-partition test-topic-replicated-2, retrying (2147483537 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:33 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 113 on topic-partition test-topic-replicated-2, retrying (2147483536 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:43 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 114 on topic-partition test-topic-replicated-2, retrying (2147483535 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:55 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 115 on topic-partition test-topic-replicated-2, retrying (2147483534 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:65 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 116 on topic-partition test-topic-replicated-2, retrying (2147483533 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:77 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 117 on topic-partition test-topic-replicated-2, retrying (2147483532 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:88 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 118 on topic-partition test-topic-replicated-2, retrying (2147483531 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:99 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 119 on topic-partition test-topic-replicated-2, retrying (2147483530 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:10 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 120 on topic-partition test-topic-replicated-2, retrying (2147483529 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:21 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 121 on topic-partition test-topic-replicated-2, retrying (2147483528 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:32 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 122 on topic-partition test-topic-replicated-2, retrying (2147483527 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:43 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 123 on topic-partition test-topic-replicated-2, retrying (2147483526 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:54 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 124 on topic-partition test-topic-replicated-2, retrying (2147483525 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:65 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 125 on topic-partition test-topic-replicated-2, retrying (2147483524 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:76 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 126 on topic-partition test-topic-replicated-2, retrying (2147483523 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:87 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 127 on topic-partition test-topic-replicated-2, retrying (2147483522 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:98 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 128 on topic-partition test-topic-replicated-2, retrying (2147483521 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:08 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 129 on topic-partition test-topic-replicated-2, retrying (2147483520 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:19 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 130 on topic-partition test-topic-replicated-2, retrying (2147483519 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:30 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 131 on topic-partition test-topic-replicated-2, retrying (2147483518 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:41 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 132 on topic-partition test-topic-replicated-2, retrying (2147483517 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:52 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 133 on topic-partition test-topic-replicated-2, retrying (2147483516 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:63 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 134 on topic-partition test-topic-replicated-2, retrying (2147483515 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:74 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 135 on topic-partition test-topic-replicated-2, retrying (2147483514 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:85 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 136 on topic-partition test-topic-replicated-2, retrying (2147483513 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:96 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 137 on topic-partition test-topic-replicated-2, retrying (2147483512 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:07 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 138 on topic-partition test-topic-replicated-2, retrying (2147483511 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:18 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 139 on topic-partition test-topic-replicated-2, retrying (2147483510 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:29 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 140 on topic-partition test-topic-replicated-2, retrying (2147483509 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:40 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 141 on topic-partition test-topic-replicated-2, retrying (2147483508 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:51 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 142 on topic-partition test-topic-replicated-2, retrying (2147483507 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:62 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 143 on topic-partition test-topic-replicated-2, retrying (2147483506 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:72 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 144 on topic-partition test-topic-replicated-2, retrying (2147483505 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:83 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 145 on topic-partition test-topic-replicated-2, retrying (2147483504 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:94 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 146 on topic-partition test-topic-replicated-2, retrying (2147483503 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:05 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 147 on topic-partition test-topic-replicated-2, retrying (2147483502 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:16 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 148 on topic-partition test-topic-replicated-2, retrying (2147483501 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:27 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 149 on topic-partition test-topic-replicated-2, retrying (2147483500 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:38 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 150 on topic-partition test-topic-replicated-2, retrying (2147483499 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:49 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 151 on topic-partition test-topic-replicated-2, retrying (2147483498 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:59 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 152 on topic-partition test-topic-replicated-2, retrying (2147483497 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:70 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 153 on topic-partition test-topic-replicated-2, retrying (2147483496 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:81 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 154 on topic-partition test-topic-replicated-2, retrying (2147483495 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:92 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 155 on topic-partition test-topic-replicated-2, retrying (2147483494 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:03 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 156 on topic-partition test-topic-replicated-2, retrying (2147483493 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:14 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 157 on topic-partition test-topic-replicated-2, retrying (2147483492 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:25 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 158 on topic-partition test-topic-replicated-2, retrying (2147483491 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:36 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 159 on topic-partition test-topic-replicated-2, retrying (2147483490 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:47 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 160 on topic-partition test-topic-replicated-2, retrying (2147483489 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:58 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 161 on topic-partition test-topic-replicated-2, retrying (2147483488 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:69 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 162 on topic-partition test-topic-replicated-2, retrying (2147483487 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:79 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 163 on topic-partition test-topic-replicated-2, retrying (2147483486 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:90 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 164 on topic-partition test-topic-replicated-2, retrying (2147483485 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:01 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 165 on topic-partition test-topic-replicated-2, retrying (2147483484 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:12 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 166 on topic-partition test-topic-replicated-2, retrying (2147483483 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:24 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 167 on topic-partition test-topic-replicated-2, retrying (2147483482 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:35 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 168 on topic-partition test-topic-replicated-2, retrying (2147483481 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:45 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 169 on topic-partition test-topic-replicated-2, retrying (2147483480 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:56 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 170 on topic-partition test-topic-replicated-2, retrying (2147483479 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:67 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 171 on topic-partition test-topic-replicated-2, retrying (2147483478 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:78 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 172 on topic-partition test-topic-replicated-2, retrying (2147483477 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:90 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 173 on topic-partition test-topic-replicated-2, retrying (2147483476 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:00 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 174 on topic-partition test-topic-replicated-2, retrying (2147483475 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:11 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 175 on topic-partition test-topic-replicated-2, retrying (2147483474 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:22 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 176 on topic-partition test-topic-replicated-2, retrying (2147483473 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:33 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 177 on topic-partition test-topic-replicated-2, retrying (2147483472 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:44 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 178 on topic-partition test-topic-replicated-2, retrying (2147483471 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:55 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 179 on topic-partition test-topic-replicated-2, retrying (2147483470 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:66 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 180 on topic-partition test-topic-replicated-2, retrying (2147483469 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:77 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 181 on topic-partition test-topic-replicated-2, retrying (2147483468 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:87 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 182 on topic-partition test-topic-replicated-2, retrying (2147483467 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:98 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 183 on topic-partition test-topic-replicated-2, retrying (2147483466 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:09 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 184 on topic-partition test-topic-replicated-2, retrying (2147483465 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:20 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 185 on topic-partition test-topic-replicated-2, retrying (2147483464 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:31 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 186 on topic-partition test-topic-replicated-2, retrying (2147483463 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:42 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 187 on topic-partition test-topic-replicated-2, retrying (2147483462 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:53 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 188 on topic-partition test-topic-replicated-2, retrying (2147483461 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:64 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 189 on topic-partition test-topic-replicated-2, retrying (2147483460 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:75 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 190 on topic-partition test-topic-replicated-2, retrying (2147483459 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:86 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 191 on topic-partition test-topic-replicated-2, retrying (2147483458 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:96 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 192 on topic-partition test-topic-replicated-2, retrying (2147483457 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:07 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 193 on topic-partition test-topic-replicated-2, retrying (2147483456 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:18 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 194 on topic-partition test-topic-replicated-2, retrying (2147483455 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:29 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 195 on topic-partition test-topic-replicated-2, retrying (2147483454 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:40 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 196 on topic-partition test-topic-replicated-2, retrying (2147483453 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:51 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 197 on topic-partition test-topic-replicated-2, retrying (2147483452 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:62 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 198 on topic-partition test-topic-replicated-2, retrying (2147483451 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:73 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 199 on topic-partition test-topic-replicated-2, retrying (2147483450 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:84 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 200 on topic-partition test-topic-replicated-2, retrying (2147483449 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:95 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 201 on topic-partition test-topic-replicated-2, retrying (2147483448 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:06 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 202 on topic-partition test-topic-replicated-2, retrying (2147483447 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:17 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 203 on topic-partition test-topic-replicated-2, retrying (2147483446 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:28 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 204 on topic-partition test-topic-replicated-2, retrying (2147483445 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:38 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 205 on topic-partition test-topic-replicated-2, retrying (2147483444 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:49 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 206 on topic-partition test-topic-replicated-2, retrying (2147483443 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:60 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 207 on topic-partition test-topic-replicated-2, retrying (2147483442 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:71 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 208 on topic-partition test-topic-replicated-2, retrying (2147483441 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:82 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 209 on topic-partition test-topic-replicated-2, retrying (2147483440 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:93 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 210 on topic-partition test-topic-replicated-2, retrying (2147483439 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:04 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 211 on topic-partition test-topic-replicated-2, retrying (2147483438 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:15 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 212 on topic-partition test-topic-replicated-2, retrying (2147483437 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:26 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 213 on topic-partition test-topic-replicated-2, retrying (2147483436 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:37 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 214 on topic-partition test-topic-replicated-2, retrying (2147483435 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:48 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 215 on topic-partition test-topic-replicated-2, retrying (2147483434 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:59 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 216 on topic-partition test-topic-replicated-2, retrying (2147483433 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:70 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 217 on topic-partition test-topic-replicated-2, retrying (2147483432 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:81 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 218 on topic-partition test-topic-replicated-2, retrying (2147483431 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:91 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 219 on topic-partition test-topic-replicated-2, retrying (2147483430 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:02 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 220 on topic-partition test-topic-replicated-2, retrying (2147483429 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:13 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 221 on topic-partition test-topic-replicated-2, retrying (2147483428 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:24 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 222 on topic-partition test-topic-replicated-2, retrying (2147483427 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:35 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 223 on topic-partition test-topic-replicated-2, retrying (2147483426 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:46 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 224 on topic-partition test-topic-replicated-2, retrying (2147483425 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:57 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 225 on topic-partition test-topic-replicated-2, retrying (2147483424 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:68 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 226 on topic-partition test-topic-replicated-2, retrying (2147483423 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:79 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 227 on topic-partition test-topic-replicated-2, retrying (2147483422 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:90 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 228 on topic-partition test-topic-replicated-2, retrying (2147483421 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:01 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 229 on topic-partition test-topic-replicated-2, retrying (2147483420 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:12 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 230 on topic-partition test-topic-replicated-2, retrying (2147483419 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:24 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 231 on topic-partition test-topic-replicated-2, retrying (2147483418 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:35 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 232 on topic-partition test-topic-replicated-2, retrying (2147483417 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:46 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 233 on topic-partition test-topic-replicated-2, retrying (2147483416 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:57 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 234 on topic-partition test-topic-replicated-2, retrying (2147483415 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:67 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 235 on topic-partition test-topic-replicated-2, retrying (2147483414 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:79 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 236 on topic-partition test-topic-replicated-2, retrying (2147483413 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:89 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 237 on topic-partition test-topic-replicated-2, retrying (2147483412 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:00 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 238 on topic-partition test-topic-replicated-2, retrying (2147483411 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:11 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 239 on topic-partition test-topic-replicated-2, retrying (2147483410 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:22 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 240 on topic-partition test-topic-replicated-2, retrying (2147483409 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:33 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 241 on topic-partition test-topic-replicated-2, retrying (2147483408 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:44 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 242 on topic-partition test-topic-replicated-2, retrying (2147483407 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:55 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 243 on topic-partition test-topic-replicated-2, retrying (2147483406 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:65 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 244 on topic-partition test-topic-replicated-2, retrying (2147483405 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:76 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 245 on topic-partition test-topic-replicated-2, retrying (2147483404 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:87 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 246 on topic-partition test-topic-replicated-2, retrying (2147483403 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:98 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 247 on topic-partition test-topic-replicated-2, retrying (2147483402 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:09 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 248 on topic-partition test-topic-replicated-2, retrying (2147483401 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:20 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 249 on topic-partition test-topic-replicated-2, retrying (2147483400 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:31 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 250 on topic-partition test-topic-replicated-2, retrying (2147483399 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:42 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 251 on topic-partition test-topic-replicated-2, retrying (2147483398 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:53 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 252 on topic-partition test-topic-replicated-2, retrying (2147483397 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:63 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 253 on topic-partition test-topic-replicated-2, retrying (2147483396 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:74 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 254 on topic-partition test-topic-replicated-2, retrying (2147483395 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:85 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 255 on topic-partition test-topic-replicated-2, retrying (2147483394 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:96 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 256 on topic-partition test-topic-replicated-2, retrying (2147483393 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:07 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 257 on topic-partition test-topic-replicated-2, retrying (2147483392 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:18 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 258 on topic-partition test-topic-replicated-2, retrying (2147483391 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:29 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 259 on topic-partition test-topic-replicated-2, retrying (2147483390 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:40 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 260 on topic-partition test-topic-replicated-2, retrying (2147483389 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:51 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 261 on topic-partition test-topic-replicated-2, retrying (2147483388 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:62 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 262 on topic-partition test-topic-replicated-2, retrying (2147483387 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:73 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 263 on topic-partition test-topic-replicated-2, retrying (2147483386 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:84 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 264 on topic-partition test-topic-replicated-2, retrying (2147483385 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:95 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 265 on topic-partition test-topic-replicated-2, retrying (2147483384 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:06 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 266 on topic-partition test-topic-replicated-2, retrying (2147483383 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:17 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 267 on topic-partition test-topic-replicated-2, retrying (2147483382 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:28 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 268 on topic-partition test-topic-replicated-2, retrying (2147483381 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:39 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 269 on topic-partition test-topic-replicated-2, retrying (2147483380 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:50 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 270 on topic-partition test-topic-replicated-2, retrying (2147483379 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:61 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 271 on topic-partition test-topic-replicated-2, retrying (2147483378 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:72 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 272 on topic-partition test-topic-replicated-2, retrying (2147483377 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:83 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 273 on topic-partition test-topic-replicated-2, retrying (2147483376 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:94 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 274 on topic-partition test-topic-replicated-2, retrying (2147483375 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:05 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 275 on topic-partition test-topic-replicated-2, retrying (2147483374 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:16 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 276 on topic-partition test-topic-replicated-2, retrying (2147483373 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:27 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 277 on topic-partition test-topic-replicated-2, retrying (2147483372 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:38 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 278 on topic-partition test-topic-replicated-2, retrying (2147483371 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:48 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 279 on topic-partition test-topic-replicated-2, retrying (2147483370 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:59 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 280 on topic-partition test-topic-replicated-2, retrying (2147483369 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:70 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 281 on topic-partition test-topic-replicated-2, retrying (2147483368 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:81 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 282 on topic-partition test-topic-replicated-2, retrying (2147483367 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:92 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 283 on topic-partition test-topic-replicated-2, retrying (2147483366 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:03 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 284 on topic-partition test-topic-replicated-2, retrying (2147483365 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:14 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 285 on topic-partition test-topic-replicated-2, retrying (2147483364 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:25 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 286 on topic-partition test-topic-replicated-2, retrying (2147483363 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:36 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 287 on topic-partition test-topic-replicated-2, retrying (2147483362 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:47 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 288 on topic-partition test-topic-replicated-2, retrying (2147483361 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:69 [main] INFO  producer.MessageProducer - Selected Option is : 1 
10:05:70 [main] INFO  producer.MessageProducer - Entered message is heyo
10:05:73 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

10:05:96 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
10:05:96 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
10:05:96 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684742036963
10:05:22 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
10:05:27 [main] INFO  producer.MessageProducer - Message heyo sent successfully for the key null
10:05:27 [main] INFO  producer.MessageProducer - Published message Offset is 0 and the partition is 1
10:05:27 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:05:77 [main] INFO  producer.MessageProducer - Entered message is heyo
10:05:77 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

10:05:77 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
10:05:77 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
10:05:77 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684742043777
10:05:83 [kafka-producer-network-thread | producer-2] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
10:05:84 [kafka-producer-network-thread | producer-2] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
10:05:85 [main] INFO  producer.MessageProducer - Message heyo sent successfully for the key null
10:05:85 [main] INFO  producer.MessageProducer - Published message Offset is 1 and the partition is 0
10:05:85 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:05:64 [main] INFO  producer.MessageProducer - Selected Option is : 1 
10:05:76 [main] INFO  producer.MessageProducer - Entered message is test
10:05:79 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 3000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

10:05:02 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
10:05:02 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
10:05:02 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684742244023
10:05:07 [kafka-producer-network-thread | producer-1] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
10:05:08 [kafka-producer-network-thread | producer-1] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
10:05:33 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
10:05:36 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 3 on topic-partition test-topic-replicated-2, retrying (2999 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:46 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 4 on topic-partition test-topic-replicated-2, retrying (2998 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:57 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 5 on topic-partition test-topic-replicated-2, retrying (2997 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:68 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 6 on topic-partition test-topic-replicated-2, retrying (2996 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:79 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 7 on topic-partition test-topic-replicated-2, retrying (2995 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:90 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 8 on topic-partition test-topic-replicated-2, retrying (2994 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:01 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 9 on topic-partition test-topic-replicated-2, retrying (2993 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:12 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 10 on topic-partition test-topic-replicated-2, retrying (2992 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:23 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 11 on topic-partition test-topic-replicated-2, retrying (2991 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:33 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 12 on topic-partition test-topic-replicated-2, retrying (2990 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:44 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 13 on topic-partition test-topic-replicated-2, retrying (2989 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:55 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 14 on topic-partition test-topic-replicated-2, retrying (2988 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:66 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 15 on topic-partition test-topic-replicated-2, retrying (2987 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:77 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 16 on topic-partition test-topic-replicated-2, retrying (2986 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:88 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 17 on topic-partition test-topic-replicated-2, retrying (2985 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:99 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 18 on topic-partition test-topic-replicated-2, retrying (2984 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:10 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 19 on topic-partition test-topic-replicated-2, retrying (2983 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:21 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 20 on topic-partition test-topic-replicated-2, retrying (2982 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:32 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 21 on topic-partition test-topic-replicated-2, retrying (2981 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:43 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 22 on topic-partition test-topic-replicated-2, retrying (2980 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:54 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 23 on topic-partition test-topic-replicated-2, retrying (2979 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:64 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 24 on topic-partition test-topic-replicated-2, retrying (2978 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:75 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 25 on topic-partition test-topic-replicated-2, retrying (2977 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:86 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 26 on topic-partition test-topic-replicated-2, retrying (2976 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:97 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 27 on topic-partition test-topic-replicated-2, retrying (2975 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:08 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 28 on topic-partition test-topic-replicated-2, retrying (2974 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:19 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 29 on topic-partition test-topic-replicated-2, retrying (2973 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:30 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 30 on topic-partition test-topic-replicated-2, retrying (2972 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:41 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 31 on topic-partition test-topic-replicated-2, retrying (2971 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:52 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 32 on topic-partition test-topic-replicated-2, retrying (2970 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:63 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 33 on topic-partition test-topic-replicated-2, retrying (2969 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:74 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 34 on topic-partition test-topic-replicated-2, retrying (2968 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:84 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 35 on topic-partition test-topic-replicated-2, retrying (2967 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:95 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 36 on topic-partition test-topic-replicated-2, retrying (2966 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:06 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 37 on topic-partition test-topic-replicated-2, retrying (2965 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:17 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 38 on topic-partition test-topic-replicated-2, retrying (2964 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:28 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 39 on topic-partition test-topic-replicated-2, retrying (2963 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:39 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 40 on topic-partition test-topic-replicated-2, retrying (2962 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:50 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 41 on topic-partition test-topic-replicated-2, retrying (2961 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:61 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 42 on topic-partition test-topic-replicated-2, retrying (2960 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:72 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 43 on topic-partition test-topic-replicated-2, retrying (2959 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:83 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 44 on topic-partition test-topic-replicated-2, retrying (2958 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:94 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 45 on topic-partition test-topic-replicated-2, retrying (2957 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:05 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 46 on topic-partition test-topic-replicated-2, retrying (2956 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:16 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 47 on topic-partition test-topic-replicated-2, retrying (2955 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:26 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 48 on topic-partition test-topic-replicated-2, retrying (2954 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:37 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 49 on topic-partition test-topic-replicated-2, retrying (2953 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:49 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 50 on topic-partition test-topic-replicated-2, retrying (2952 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:59 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 51 on topic-partition test-topic-replicated-2, retrying (2951 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:70 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 52 on topic-partition test-topic-replicated-2, retrying (2950 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:81 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 53 on topic-partition test-topic-replicated-2, retrying (2949 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:92 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 54 on topic-partition test-topic-replicated-2, retrying (2948 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:03 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 55 on topic-partition test-topic-replicated-2, retrying (2947 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:14 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 56 on topic-partition test-topic-replicated-2, retrying (2946 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:25 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 57 on topic-partition test-topic-replicated-2, retrying (2945 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:36 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 58 on topic-partition test-topic-replicated-2, retrying (2944 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:47 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 59 on topic-partition test-topic-replicated-2, retrying (2943 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:58 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 60 on topic-partition test-topic-replicated-2, retrying (2942 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:69 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 61 on topic-partition test-topic-replicated-2, retrying (2941 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:79 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 62 on topic-partition test-topic-replicated-2, retrying (2940 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:90 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 63 on topic-partition test-topic-replicated-2, retrying (2939 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:01 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 64 on topic-partition test-topic-replicated-2, retrying (2938 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:12 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 65 on topic-partition test-topic-replicated-2, retrying (2937 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:23 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 66 on topic-partition test-topic-replicated-2, retrying (2936 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:34 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 67 on topic-partition test-topic-replicated-2, retrying (2935 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:45 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 68 on topic-partition test-topic-replicated-2, retrying (2934 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:56 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 69 on topic-partition test-topic-replicated-2, retrying (2933 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:67 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 70 on topic-partition test-topic-replicated-2, retrying (2932 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:78 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 71 on topic-partition test-topic-replicated-2, retrying (2931 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:89 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 72 on topic-partition test-topic-replicated-2, retrying (2930 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:00 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 73 on topic-partition test-topic-replicated-2, retrying (2929 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:11 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 74 on topic-partition test-topic-replicated-2, retrying (2928 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:22 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 75 on topic-partition test-topic-replicated-2, retrying (2927 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:33 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 76 on topic-partition test-topic-replicated-2, retrying (2926 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:43 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 77 on topic-partition test-topic-replicated-2, retrying (2925 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:54 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 78 on topic-partition test-topic-replicated-2, retrying (2924 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:65 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 79 on topic-partition test-topic-replicated-2, retrying (2923 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:76 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 80 on topic-partition test-topic-replicated-2, retrying (2922 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:87 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 81 on topic-partition test-topic-replicated-2, retrying (2921 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:98 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 82 on topic-partition test-topic-replicated-2, retrying (2920 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:09 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 83 on topic-partition test-topic-replicated-2, retrying (2919 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:20 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 84 on topic-partition test-topic-replicated-2, retrying (2918 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:31 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 85 on topic-partition test-topic-replicated-2, retrying (2917 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:42 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 86 on topic-partition test-topic-replicated-2, retrying (2916 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:53 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 87 on topic-partition test-topic-replicated-2, retrying (2915 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:64 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 88 on topic-partition test-topic-replicated-2, retrying (2914 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:75 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 89 on topic-partition test-topic-replicated-2, retrying (2913 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:86 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 90 on topic-partition test-topic-replicated-2, retrying (2912 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:97 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 91 on topic-partition test-topic-replicated-2, retrying (2911 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:07 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 92 on topic-partition test-topic-replicated-2, retrying (2910 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:18 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 93 on topic-partition test-topic-replicated-2, retrying (2909 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:30 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 94 on topic-partition test-topic-replicated-2, retrying (2908 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:41 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 95 on topic-partition test-topic-replicated-2, retrying (2907 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:51 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 96 on topic-partition test-topic-replicated-2, retrying (2906 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:62 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 97 on topic-partition test-topic-replicated-2, retrying (2905 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:73 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 98 on topic-partition test-topic-replicated-2, retrying (2904 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:84 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 99 on topic-partition test-topic-replicated-2, retrying (2903 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:95 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 100 on topic-partition test-topic-replicated-2, retrying (2902 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:06 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 101 on topic-partition test-topic-replicated-2, retrying (2901 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:17 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 102 on topic-partition test-topic-replicated-2, retrying (2900 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:28 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 103 on topic-partition test-topic-replicated-2, retrying (2899 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:39 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 104 on topic-partition test-topic-replicated-2, retrying (2898 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:50 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 105 on topic-partition test-topic-replicated-2, retrying (2897 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:61 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 106 on topic-partition test-topic-replicated-2, retrying (2896 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:72 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 107 on topic-partition test-topic-replicated-2, retrying (2895 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:83 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 108 on topic-partition test-topic-replicated-2, retrying (2894 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:94 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 109 on topic-partition test-topic-replicated-2, retrying (2893 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:05 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 110 on topic-partition test-topic-replicated-2, retrying (2892 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:16 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 111 on topic-partition test-topic-replicated-2, retrying (2891 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:27 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 112 on topic-partition test-topic-replicated-2, retrying (2890 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:38 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 113 on topic-partition test-topic-replicated-2, retrying (2889 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:48 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 114 on topic-partition test-topic-replicated-2, retrying (2888 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:89 [main] INFO  producer.MessageProducer - Selected Option is : 1 
10:05:89 [main] INFO  producer.MessageProducer - Entered message is haha
10:05:93 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

10:05:15 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
10:05:15 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
10:05:15 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684742294153
10:05:21 [kafka-producer-network-thread | producer-1] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
10:05:46 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
10:05:48 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 3 on topic-partition test-topic-replicated-1, retrying (9 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:49 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 4 on topic-partition test-topic-replicated-1, retrying (8 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:50 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 5 on topic-partition test-topic-replicated-1, retrying (7 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:50 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 6 on topic-partition test-topic-replicated-1, retrying (6 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:51 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 7 on topic-partition test-topic-replicated-1, retrying (5 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:51 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 8 on topic-partition test-topic-replicated-1, retrying (4 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:52 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 9 on topic-partition test-topic-replicated-1, retrying (3 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:53 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 10 on topic-partition test-topic-replicated-1, retrying (2 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:54 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 11 on topic-partition test-topic-replicated-1, retrying (1 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:55 [kafka-producer-network-thread | producer-1] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 12 on topic-partition test-topic-replicated-1, retrying (0 attempts left). Error: NOT_ENOUGH_REPLICAS
10:05:56 [main] ERROR producer.MessageProducer - Exception in publishMessageSync : org.apache.kafka.common.errors.NotEnoughReplicasException: Messages are rejected since there are fewer in-sync replicas than required.
10:05:56 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:05:48 [main] INFO  producer.MessageProducer - Selected Option is : 1 
10:05:49 [main] INFO  producer.MessageProducer - Entered message is hehe
10:05:52 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

10:05:75 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
10:05:75 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
10:05:75 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684742356748
10:05:02 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
10:05:06 [main] INFO  producer.MessageProducer - Message hehe sent successfully for the key null
10:05:06 [main] INFO  producer.MessageProducer - Published message Offset is 2 and the partition is 0
10:05:06 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
10:05:53 [main] INFO  producer.MessageProducer - Entered message is 00
10:05:53 [main] INFO  producer.MessageProducer - Exiting from Option : 1
10:05:55 [main] INFO  producer.MessageProducer - Selected Option is : 2 
12:05:22 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

12:05:48 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
12:05:48 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
12:05:48 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684747457484
12:05:49 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer-1, groupId=MessageConsumer] Subscribed to topic(s): test-topic-replicated
12:05:76 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer-1, groupId=MessageConsumer] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
12:05:76 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer-1, groupId=MessageConsumer] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
12:05:76 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer-1, groupId=MessageConsumer] (Re-)joining group
12:05:77 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer-1, groupId=MessageConsumer] (Re-)joining group
12:05:78 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer-1, groupId=MessageConsumer] Finished assignment for group at generation 1: {consumer-MessageConsumer-1-2b6d85c1-240e-4862-a428-960888273bdb=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6d366c9b}
12:05:78 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer-1, groupId=MessageConsumer] Successfully joined group with generation 1
12:05:79 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer-1, groupId=MessageConsumer] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
12:05:80 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer-1, groupId=MessageConsumer] Found no committed offset for partition test-topic-replicated-0
12:05:80 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer-1, groupId=MessageConsumer] Found no committed offset for partition test-topic-replicated-1
12:05:80 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer-1, groupId=MessageConsumer] Found no committed offset for partition test-topic-replicated-2
12:05:82 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer-1, groupId=MessageConsumer] Resetting offset for partition test-topic-replicated-0 to offset 3.
12:05:82 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer-1, groupId=MessageConsumer] Resetting offset for partition test-topic-replicated-1 to offset 1.
12:05:82 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer-1, groupId=MessageConsumer] Resetting offset for partition test-topic-replicated-2 to offset 0.
12:05:84 [main] INFO  producer.MessageProducer - Selected Option is : 1 
12:05:89 [main] INFO  producer.MessageProducer - Entered message is Welcome my friend
12:05:93 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

12:05:16 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
12:05:16 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
12:05:16 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684747541163
12:05:43 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
12:05:47 [main] INFO  producer.MessageProducer - Message Welcome my friend sent successfully for the key null
12:05:47 [main] INFO  producer.MessageProducer - Published message Offset is 1 and the partition is 1
12:05:47 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
12:05:48 [main] INFO  consumer.MessageConsumer - Consumer Record key is null and the value is Welcome my friend and the partition is 1
12:05:39 [main] INFO  producer.MessageProducer - Entered message is A-apple
12:05:39 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

12:05:39 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
12:05:39 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
12:05:40 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684747590399
12:05:40 [kafka-producer-network-thread | producer-2] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
12:05:41 [main] INFO  consumer.MessageConsumer - Consumer Record key is A and the value is apple and the partition is 1
12:05:41 [main] INFO  producer.MessageProducer - Message apple sent successfully for the key A
12:05:41 [main] INFO  producer.MessageProducer - Published message Offset is 2 and the partition is 1
12:05:41 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
12:05:41 [main] INFO  producer.MessageProducer - Entered message is a
12:05:41 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

12:05:42 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
12:05:42 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
12:05:42 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684747697425
12:05:47 [kafka-producer-network-thread | producer-3] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
12:05:47 [kafka-producer-network-thread | producer-3] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-3] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
12:05:48 [main] INFO  producer.MessageProducer - Message a sent successfully for the key null
12:05:49 [main] INFO  producer.MessageProducer - Published message Offset is 3 and the partition is 1
12:05:49 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
12:05:49 [main] INFO  consumer.MessageConsumer - Consumer Record key is null and the value is a and the partition is 1
12:05:49 [main] INFO  producer.MessageProducer - Entered message is b
12:05:49 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

12:05:49 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
12:05:49 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
12:05:49 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684747699498
12:05:50 [kafka-producer-network-thread | producer-4] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-4] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
12:05:51 [main] INFO  consumer.MessageConsumer - Consumer Record key is null and the value is b and the partition is 1
12:05:51 [main] INFO  producer.MessageProducer - Message b sent successfully for the key null
12:05:51 [main] INFO  producer.MessageProducer - Published message Offset is 4 and the partition is 1
12:05:51 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-4] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
12:05:44 [main] INFO  producer.MessageProducer - Entered message is 
12:05:44 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

12:05:44 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
12:05:44 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
12:05:44 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684747700446
12:05:44 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-5] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
12:05:45 [main] INFO  producer.MessageProducer - Entered message is c
12:05:45 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

12:05:45 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
12:05:45 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
12:05:45 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684747701458
12:05:50 [kafka-producer-network-thread | producer-6] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-6] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
12:05:51 [kafka-producer-network-thread | producer-6] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-6] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
12:05:51 [main] INFO  producer.MessageProducer - Message c sent successfully for the key null
12:05:51 [main] INFO  consumer.MessageConsumer - Consumer Record key is null and the value is c and the partition is 1
12:05:51 [main] INFO  producer.MessageProducer - Published message Offset is 5 and the partition is 1
12:05:51 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-6] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
12:05:52 [main] INFO  producer.MessageProducer - Entered message is ghi
12:05:52 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

12:05:52 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
12:05:52 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
12:05:52 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684747703524
12:05:57 [kafka-producer-network-thread | producer-7] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-7] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
12:05:58 [kafka-producer-network-thread | producer-7] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-7] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
12:05:59 [main] INFO  producer.MessageProducer - Message ghi sent successfully for the key null
12:05:59 [main] INFO  producer.MessageProducer - Published message Offset is 3 and the partition is 0
12:05:59 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-7] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
12:05:59 [main] INFO  consumer.MessageConsumer - Consumer Record key is null and the value is ghi and the partition is 0
12:05:84 [main] INFO  producer.MessageProducer - Entered message is haha
12:05:84 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

12:05:85 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
12:05:85 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
12:05:85 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684747741853
12:05:85 [kafka-producer-network-thread | producer-8] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-8] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
12:05:86 [main] INFO  producer.MessageProducer - Message haha sent successfully for the key null
12:05:86 [main] INFO  producer.MessageProducer - Published message Offset is 6 and the partition is 1
12:05:86 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-8] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
12:05:88 [main] INFO  producer.MessageProducer - Entered message is bebe
12:05:88 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

12:05:88 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
12:05:88 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
12:05:88 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684747744887
12:05:89 [kafka-producer-network-thread | producer-9] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-9] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
12:05:90 [main] INFO  producer.MessageProducer - Message bebe sent successfully for the key null
12:05:90 [main] INFO  producer.MessageProducer - Published message Offset is 0 and the partition is 2
12:05:90 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-9] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
12:05:90 [main] INFO  producer.MessageProducer - Entered message is trrrt
12:05:90 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

12:05:91 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
12:05:91 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
12:05:91 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684747746910
12:05:91 [kafka-producer-network-thread | producer-10] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-10] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
12:05:92 [main] INFO  producer.MessageProducer - Message trrrt sent successfully for the key null
12:05:92 [main] INFO  producer.MessageProducer - Published message Offset is 4 and the partition is 0
12:05:92 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-10] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
12:05:60 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

12:05:85 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
12:05:85 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
12:05:85 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684747751855
12:05:86 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer-1, groupId=MessageConsumer] Subscribed to topic(s): test-topic-replicated
12:05:04 [main] WARN  o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-MessageConsumer-1, groupId=MessageConsumer] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
12:05:16 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer-1, groupId=MessageConsumer] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
12:05:16 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer-1, groupId=MessageConsumer] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
12:05:17 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer-1, groupId=MessageConsumer] (Re-)joining group
12:05:18 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer-1, groupId=MessageConsumer] (Re-)joining group
12:05:18 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer-1, groupId=MessageConsumer] Finished assignment for group at generation 3: {consumer-MessageConsumer-1-7a4d046a-53d9-4d76-8ad9-0b8c3e92ae6f=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@569bf9eb}
12:05:19 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer-1, groupId=MessageConsumer] Successfully joined group with generation 3
12:05:19 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer-1, groupId=MessageConsumer] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
12:05:20 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer-1, groupId=MessageConsumer] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
12:05:20 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer-1, groupId=MessageConsumer] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
12:05:20 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer-1, groupId=MessageConsumer] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
12:05:24 [main] INFO  consumer.MessageConsumer - Consumer Record key is null and the value is bebe and the partition is 2
12:05:75 [main] INFO  consumer.MessageConsumer - Consumer Record key is null and the value is trrrt and the partition is 0
12:05:75 [main] INFO  consumer.MessageConsumer - Consumer Record key is null and the value is haha and the partition is 1
12:05:79 [main] INFO  producer.MessageProducer - Entered message is tehkts
12:05:79 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

12:05:80 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
12:05:80 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
12:05:80 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684747835804
12:05:84 [kafka-producer-network-thread | producer-11] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-11] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
12:05:85 [kafka-producer-network-thread | producer-11] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-11] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
12:05:86 [main] INFO  producer.MessageProducer - Message tehkts sent successfully for the key null
12:05:86 [main] INFO  producer.MessageProducer - Published message Offset is 1 and the partition is 2
12:05:86 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-11] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
12:05:82 [main] INFO  producer.MessageProducer - Entered message is 
12:05:82 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

12:05:83 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
12:05:83 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
12:05:83 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684747838831
12:05:83 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-12] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
12:05:42 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

12:05:67 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
12:05:67 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
12:05:67 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684747842672
12:05:67 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer1-1, groupId=MessageConsumer1] Subscribed to topic(s): test-topic-replicated
12:05:93 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer1-1, groupId=MessageConsumer1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
12:05:94 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer1-1, groupId=MessageConsumer1] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
12:05:94 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer1-1, groupId=MessageConsumer1] (Re-)joining group
12:05:95 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer1-1, groupId=MessageConsumer1] (Re-)joining group
12:05:95 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer1-1, groupId=MessageConsumer1] Finished assignment for group at generation 1: {consumer-MessageConsumer1-1-4fe8016d-989c-49bf-bf4f-d9a989668d22=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6d366c9b}
12:05:96 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer1-1, groupId=MessageConsumer1] Successfully joined group with generation 1
12:05:96 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer1-1, groupId=MessageConsumer1] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
12:05:97 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer1-1, groupId=MessageConsumer1] Found no committed offset for partition test-topic-replicated-0
12:05:97 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer1-1, groupId=MessageConsumer1] Found no committed offset for partition test-topic-replicated-1
12:05:97 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer1-1, groupId=MessageConsumer1] Found no committed offset for partition test-topic-replicated-2
12:05:98 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer1-1, groupId=MessageConsumer1] Resetting offset for partition test-topic-replicated-0 to offset 5.
12:05:98 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer1-1, groupId=MessageConsumer1] Resetting offset for partition test-topic-replicated-1 to offset 7.
12:05:98 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer1-1, groupId=MessageConsumer1] Resetting offset for partition test-topic-replicated-2 to offset 2.
12:05:26 [main] INFO  producer.MessageProducer - Entered message is testtttt
12:05:26 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

12:05:26 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
12:05:26 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
12:05:26 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684747886267
12:05:27 [kafka-producer-network-thread | producer-13] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-13] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
12:05:27 [main] INFO  producer.MessageProducer - Message testtttt sent successfully for the key null
12:05:27 [main] INFO  producer.MessageProducer - Published message Offset is 5 and the partition is 0
12:05:27 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-13] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
12:05:29 [main] INFO  consumer.MessageConsumer - Consumer Record key is null and the value is testtttt and the partition is 0
12:05:25 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

12:05:50 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
12:05:50 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
12:05:50 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684747962505
12:05:51 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Subscribed to topic(s): test-topic-replicated
12:05:77 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
12:05:77 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
12:05:78 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
12:05:78 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
12:05:79 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 1: {consumer-MessageConsumer2-1-58f3244e-4cb5-49b4-b27e-b76a11326f51=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6d366c9b}
12:05:79 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 1
12:05:80 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
12:05:80 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition test-topic-replicated-0
12:05:80 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition test-topic-replicated-1
12:05:80 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition test-topic-replicated-2
12:05:82 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition test-topic-replicated-0 to offset 0.
12:05:82 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition test-topic-replicated-1 to offset 0.
12:05:82 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition test-topic-replicated-2 to offset 0.
12:05:85 [main] INFO  consumer.MessageConsumer - Consumer Record key is null and the value is Welcome my child and the partition is 0
12:05:85 [main] INFO  consumer.MessageConsumer - Consumer Record key is null and the value is heyo and the partition is 0
12:05:85 [main] INFO  consumer.MessageConsumer - Consumer Record key is null and the value is hehe and the partition is 0
12:05:85 [main] INFO  consumer.MessageConsumer - Consumer Record key is null and the value is ghi and the partition is 0
12:05:85 [main] INFO  consumer.MessageConsumer - Consumer Record key is null and the value is trrrt and the partition is 0
12:05:85 [main] INFO  consumer.MessageConsumer - Consumer Record key is null and the value is testtttt and the partition is 0
12:05:85 [main] INFO  consumer.MessageConsumer - Consumer Record key is null and the value is heyo and the partition is 1
12:05:85 [main] INFO  consumer.MessageConsumer - Consumer Record key is null and the value is Welcome my friend and the partition is 1
12:05:85 [main] INFO  consumer.MessageConsumer - Consumer Record key is A and the value is apple and the partition is 1
12:05:85 [main] INFO  consumer.MessageConsumer - Consumer Record key is null and the value is a and the partition is 1
12:05:85 [main] INFO  consumer.MessageConsumer - Consumer Record key is null and the value is b and the partition is 1
12:05:85 [main] INFO  consumer.MessageConsumer - Consumer Record key is null and the value is c and the partition is 1
12:05:85 [main] INFO  consumer.MessageConsumer - Consumer Record key is null and the value is haha and the partition is 1
12:05:85 [main] INFO  consumer.MessageConsumer - Consumer Record key is null and the value is bebe and the partition is 2
12:05:85 [main] INFO  consumer.MessageConsumer - Consumer Record key is null and the value is tehkts and the partition is 2
14:05:31 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

14:05:59 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
14:05:59 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
14:05:59 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684753690594
14:05:60 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Subscribed to topic(s): test-topic-replicated
14:05:90 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
14:05:90 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
14:05:91 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:91 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:92 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 3: {consumer-MessageConsumer2-1-06c57107-1f33-4f39-ad5d-86b351c0f6b6=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6d366c9b}
14:05:92 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 3
14:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
14:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=2, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:94 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:94 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:02 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

14:05:35 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
14:05:35 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
14:05:35 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684753701348
14:05:35 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Subscribed to topic(s): test-topic-replicated
14:05:71 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
14:05:71 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
14:05:71 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:73 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:95 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:95 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
14:05:95 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:96 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 4: {consumer-MessageConsumer2-1-39c7bf8c-e6da-456f-9177-f743913e82f9=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@3954d008, consumer-MessageConsumer2-1-06c57107-1f33-4f39-ad5d-86b351c0f6b6=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@2f94c4db}
14:05:96 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 4
14:05:96 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 4
14:05:96 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1
14:05:96 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:96 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:97 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=2, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:85 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

14:05:14 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
14:05:14 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
14:05:14 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684753704141
14:05:15 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Subscribed to topic(s): test-topic-replicated
14:05:45 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
14:05:45 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
14:05:46 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:47 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:97 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:97 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-0, test-topic-replicated-1
14:05:97 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:97 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:97 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-2
14:05:98 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 5: {consumer-MessageConsumer2-1-39c7bf8c-e6da-456f-9177-f743913e82f9=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6d8792db, consumer-MessageConsumer2-1-40a7cb84-6800-4cda-b618-0edd62c60323=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@64bc21ac, consumer-MessageConsumer2-1-06c57107-1f33-4f39-ad5d-86b351c0f6b6=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@493dfb8e}
14:05:98 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 5
14:05:98 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 5
14:05:98 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 5
14:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0
14:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-1
14:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:00 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=2, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:44 [main] INFO  producer.MessageProducer - Selected Option is : 1 
14:05:46 [main] INFO  producer.MessageProducer - Entered message is Heyo
14:05:49 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

14:05:73 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
14:05:73 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
14:05:73 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684753892732
14:05:79 [kafka-producer-network-thread | producer-1] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
14:05:06 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
14:05:10 [main] INFO  producer.MessageProducer - Message Heyo sent successfully for the key null
14:05:10 [main] INFO  producer.MessageProducer - Published message Offset is 6 and the partition is 0
14:05:10 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
14:05:11 [main] INFO  consumer.MessageConsumer - Consumer Record key is null and the value is Heyo and the partition is 0
14:05:97 [main] INFO  producer.MessageProducer - Selected Option is : 1 
14:05:02 [main] INFO  producer.MessageProducer - Entered message is next
14:05:05 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

14:05:28 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
14:05:28 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
14:05:28 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684753996282
14:05:55 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
14:05:59 [main] INFO  producer.MessageProducer - Message next sent successfully for the key null
14:05:59 [main] INFO  producer.MessageProducer - Published message Offset is 2 and the partition is 2
14:05:59 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
14:05:60 [main] INFO  consumer.MessageConsumer2 - Consumer Record key is null and the value is next and the partition is 2
14:05:04 [main] INFO  producer.MessageProducer - Entered message is haha
14:05:05 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

14:05:05 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
14:05:05 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
14:05:05 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684754000056
14:05:10 [kafka-producer-network-thread | producer-2] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
14:05:11 [kafka-producer-network-thread | producer-2] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
14:05:11 [main] INFO  producer.MessageProducer - Message haha sent successfully for the key null
14:05:11 [main] INFO  producer.MessageProducer - Published message Offset is 7 and the partition is 1
14:05:11 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
14:05:13 [main] INFO  consumer.MessageConsumer1 - Consumer Record key is null and the value is haha and the partition is 1
14:05:13 [main] INFO  producer.MessageProducer - Entered message is prrrt
14:05:13 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

14:05:13 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
14:05:13 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
14:05:13 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684754007136
14:05:14 [kafka-producer-network-thread | producer-3] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-3] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
14:05:15 [main] INFO  consumer.MessageConsumer2 - Consumer Record key is null and the value is prrrt and the partition is 2
14:05:15 [main] INFO  producer.MessageProducer - Message prrrt sent successfully for the key null
14:05:15 [main] INFO  producer.MessageProducer - Published message Offset is 3 and the partition is 2
14:05:15 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
14:05:00 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

14:05:25 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
14:05:25 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
14:05:25 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684754746255
14:05:26 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Subscribed to topic(s): test-topic-replicated
14:05:52 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
14:05:53 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
14:05:53 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:54 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:64 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 6: {consumer-MessageConsumer2-1-b0d2dec1-84f3-4052-b1a3-8625c15fd81d=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6d366c9b}
14:05:64 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 6
14:05:65 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
14:05:66 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:66 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:66 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:57 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

14:05:84 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
14:05:85 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
14:05:85 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684754823847
14:05:85 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Subscribed to topic(s): test-topic-replicated
14:05:02 [main] WARN  o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
14:05:15 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
14:05:15 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
14:05:15 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:16 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:83 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:83 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
14:05:83 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:84 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 7: {consumer-MessageConsumer2-1-eb29225b-27b2-44bb-b3da-f64149c78f75=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@3954d008, consumer-MessageConsumer2-1-b0d2dec1-84f3-4052-b1a3-8625c15fd81d=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@2f94c4db}
14:05:84 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 7
14:05:84 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1
14:05:84 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 7
14:05:84 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:84 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:84 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:85 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:66 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

14:05:92 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
14:05:92 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
14:05:92 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684754863924
14:05:93 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Subscribed to topic(s): test-topic-replicated
14:05:20 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
14:05:20 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
14:05:20 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:21 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:93 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:93 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-0, test-topic-replicated-1
14:05:93 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-2
14:05:93 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 8: {consumer-MessageConsumer2-1-a8724614-3273-42ca-b49a-8485276e2412=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6d8792db, consumer-MessageConsumer2-1-eb29225b-27b2-44bb-b3da-f64149c78f75=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@64bc21ac, consumer-MessageConsumer2-1-b0d2dec1-84f3-4052-b1a3-8625c15fd81d=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@493dfb8e}
14:05:94 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 8
14:05:94 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 8
14:05:94 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-1
14:05:94 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:94 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 8
14:05:94 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:94 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:94 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0
14:05:95 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:38 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

14:05:63 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
14:05:63 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
14:05:63 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684754886634
14:05:64 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Subscribed to topic(s): test-topic-replicated
14:05:91 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
14:05:91 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
14:05:91 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:92 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:99 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:99 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-1
14:05:99 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-0
14:05:99 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:97 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 9: {consumer-MessageConsumer2-1-a8724614-3273-42ca-b49a-8485276e2412=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@5d25e6bb, consumer-MessageConsumer2-1-cf235319-9ff4-472b-8890-59b838706154=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@ce5a68e, consumer-MessageConsumer2-1-b0d2dec1-84f3-4052-b1a3-8625c15fd81d=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@9d157ff}
14:05:97 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 9
14:05:97 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 9
14:05:97 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-1
14:05:97 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0
14:05:97 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 9
14:05:97 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:97 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:97 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:02 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

14:05:27 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
14:05:27 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
14:05:27 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684754961274
14:05:28 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Subscribed to topic(s): test-topic-replicated
14:05:55 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
14:05:55 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
14:05:56 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:56 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:09 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 10: {consumer-MessageConsumer2-1-36802a16-d27d-4938-bb28-7c45dc38866d=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6d366c9b}
14:05:09 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 10
14:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
14:05:11 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:11 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:11 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:37 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

14:05:63 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
14:05:63 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
14:05:63 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684754973629
14:05:63 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Subscribed to topic(s): test-topic-replicated
14:05:90 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
14:05:90 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
14:05:90 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:91 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:14 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:14 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
14:05:14 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:14 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 11: {consumer-MessageConsumer2-1-8896c169-76bc-4348-a66b-240619301474=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@3954d008, consumer-MessageConsumer2-1-36802a16-d27d-4938-bb28-7c45dc38866d=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@2f94c4db}
14:05:15 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 11
14:05:15 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1
14:05:15 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 11
14:05:15 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:15 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:15 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:16 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:52 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

14:05:77 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
14:05:78 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
14:05:78 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684755000777
14:05:78 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Subscribed to topic(s): test-topic-replicated
14:05:04 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
14:05:04 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
14:05:05 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:05 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:19 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:19 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:19 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-0, test-topic-replicated-1
14:05:19 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:19 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-2
14:05:19 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:19 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 12: {consumer-MessageConsumer2-1-a9368041-4997-4e07-8ec4-3d8b3885feda=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6d8792db, consumer-MessageConsumer2-1-8896c169-76bc-4348-a66b-240619301474=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@64bc21ac, consumer-MessageConsumer2-1-36802a16-d27d-4938-bb28-7c45dc38866d=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@493dfb8e}
14:05:19 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 12
14:05:19 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 12
14:05:19 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-1
14:05:19 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0
14:05:19 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 12
14:05:20 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:20 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:20 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:21 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:77 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 5000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

14:05:02 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
14:05:03 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
14:05:03 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684755521027
14:05:03 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Subscribed to topic(s): test-topic-replicated
14:05:37 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:37 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-2
14:05:37 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:45 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:45 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-1
14:05:45 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:46 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 13: {consumer-MessageConsumer2-1-a9368041-4997-4e07-8ec4-3d8b3885feda=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6a1d204a, consumer-MessageConsumer2-1-8896c169-76bc-4348-a66b-240619301474=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@62dae245}
14:05:46 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 13
14:05:46 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 13
14:05:46 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1
14:05:46 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:46 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:46 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:46 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:31 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
14:05:31 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
14:05:31 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:32 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:47 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:47 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:47 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-2
14:05:47 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:47 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-0, test-topic-replicated-1
14:05:47 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:47 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 14: {consumer-MessageConsumer2-1-a9368041-4997-4e07-8ec4-3d8b3885feda=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6fff253c, consumer-MessageConsumer2-1-8896c169-76bc-4348-a66b-240619301474=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6c6357f9, consumer-MessageConsumer2-1-610e5cee-045e-4666-b8c2-730bbe1d667c=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@591e58fa}
14:05:47 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 14
14:05:47 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-1
14:05:47 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 14
14:05:47 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:47 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:47 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:42 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 14
14:05:42 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0
14:05:43 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:55 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-610e5cee-045e-4666-b8c2-730bbe1d667c sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:54 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
14:05:54 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=7, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:54 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
14:05:54 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0
14:05:54 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:55 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:51 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:51 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:51 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-1
14:05:51 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:51 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-2
14:05:51 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:52 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 15: {consumer-MessageConsumer2-1-a9368041-4997-4e07-8ec4-3d8b3885feda=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@ce5a68e, consumer-MessageConsumer2-1-8896c169-76bc-4348-a66b-240619301474=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@9d157ff, consumer-MessageConsumer2-1-1d7b334a-670e-462e-9430-1fca36dc006d=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@2f162cc0}
14:05:52 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 15
14:05:52 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-1
14:05:52 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 15
14:05:52 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:52 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:52 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:66 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 15
14:05:66 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0
14:05:66 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:67 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-1d7b334a-670e-462e-9430-1fca36dc006d sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:78 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
14:05:78 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=7, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:78 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
14:05:78 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0
14:05:78 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:78 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:55 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:55 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-1
14:05:55 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:57 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:57 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-2
14:05:57 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:57 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 16: {consumer-MessageConsumer2-1-acf3efd6-5754-4d79-87e6-4d367f2048db=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@5df417a7, consumer-MessageConsumer2-1-a9368041-4997-4e07-8ec4-3d8b3885feda=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@7c041b41, consumer-MessageConsumer2-1-8896c169-76bc-4348-a66b-240619301474=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@7f69d591}
14:05:57 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 16
14:05:57 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 16
14:05:57 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-1
14:05:57 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0
14:05:57 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:57 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:90 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 16
14:05:90 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:90 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:92 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-acf3efd6-5754-4d79-87e6-4d367f2048db sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:02 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
14:05:02 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-2=OffsetAndMetadata{offset=4, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:02 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
14:05:02 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-2
14:05:02 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:02 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:60 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:60 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:60 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-0
14:05:60 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:60 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-1
14:05:60 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:60 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 17: {consumer-MessageConsumer2-1-a9368041-4997-4e07-8ec4-3d8b3885feda=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@2cab9998, consumer-MessageConsumer2-1-8896c169-76bc-4348-a66b-240619301474=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@2f7a7219, consumer-MessageConsumer2-1-64bac6fa-d83e-412c-919a-3eeabf02d326=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@669513d8}
14:05:60 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 17
14:05:60 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 17
14:05:60 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:60 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-1
14:05:61 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:61 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:14 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 17
14:05:14 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0
14:05:14 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:14 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-64bac6fa-d83e-412c-919a-3eeabf02d326 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:25 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
14:05:25 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=7, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:25 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
14:05:25 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0
14:05:25 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:25 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:62 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:62 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:62 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-2
14:05:62 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:62 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-1
14:05:62 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:62 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 18: {consumer-MessageConsumer2-1-a9368041-4997-4e07-8ec4-3d8b3885feda=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@361c294e, consumer-MessageConsumer2-1-8896c169-76bc-4348-a66b-240619301474=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@7859e786, consumer-MessageConsumer2-1-f958aeb1-f7c1-4ac2-8254-c5c9fc5738f3=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@285d851a}
14:05:62 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 18
14:05:62 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 18
14:05:62 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0
14:05:62 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-1
14:05:62 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:62 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:36 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 18
14:05:36 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:37 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:37 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-f958aeb1-f7c1-4ac2-8254-c5c9fc5738f3 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:49 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
14:05:49 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-2=OffsetAndMetadata{offset=4, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:49 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
14:05:49 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-2
14:05:49 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:49 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:66 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:66 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:67 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-1
14:05:67 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:67 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-0
14:05:67 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:67 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 19: {consumer-MessageConsumer2-1-a9368041-4997-4e07-8ec4-3d8b3885feda=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@5118388b, consumer-MessageConsumer2-1-8896c169-76bc-4348-a66b-240619301474=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@15a902e7, consumer-MessageConsumer2-1-5f031f97-b6d3-4312-89ca-9f6f1b2fb785=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@7876d598}
14:05:67 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 19
14:05:67 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 19
14:05:67 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-1
14:05:67 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:67 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:67 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:61 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 19
14:05:61 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0
14:05:61 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:62 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-5f031f97-b6d3-4312-89ca-9f6f1b2fb785 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:73 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
14:05:73 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=7, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:73 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
14:05:73 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0
14:05:73 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:73 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:70 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:70 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:70 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-1
14:05:70 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:70 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-2
14:05:70 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:70 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 20: {consumer-MessageConsumer2-1-a9368041-4997-4e07-8ec4-3d8b3885feda=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@71104a4, consumer-MessageConsumer2-1-8896c169-76bc-4348-a66b-240619301474=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@4985cbcb, consumer-MessageConsumer2-1-4459f75c-51be-4cae-aa2d-8b04adf2ef50=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@72f46e16}
14:05:70 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 20
14:05:70 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 20
14:05:70 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-1
14:05:70 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:71 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:71 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:85 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 20
14:05:85 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0
14:05:85 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:86 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-4459f75c-51be-4cae-aa2d-8b04adf2ef50 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:97 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
14:05:97 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=7, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:97 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
14:05:97 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0
14:05:97 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:97 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:74 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:74 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:74 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-1
14:05:74 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:74 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-2
14:05:74 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:74 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 21: {consumer-MessageConsumer2-1-a9368041-4997-4e07-8ec4-3d8b3885feda=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@3c9168dc, consumer-MessageConsumer2-1-8896c169-76bc-4348-a66b-240619301474=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@332a7fce, consumer-MessageConsumer2-1-354c24d4-136e-4bfa-a19b-085af93483d3=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@549621f3}
14:05:74 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 21
14:05:74 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 21
14:05:74 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:74 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-1
14:05:74 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:74 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:09 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 21
14:05:09 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0
14:05:09 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:20 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-354c24d4-136e-4bfa-a19b-085af93483d3 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:21 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
14:05:21 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=7, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:21 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
14:05:21 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0
14:05:21 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:21 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:78 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:78 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:78 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-2
14:05:78 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:78 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-1
14:05:78 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:78 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 22: {consumer-MessageConsumer2-1-a9368041-4997-4e07-8ec4-3d8b3885feda=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@54361a9, consumer-MessageConsumer2-1-8896c169-76bc-4348-a66b-240619301474=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@32232e55, consumer-MessageConsumer2-1-89d64236-8f83-4a2c-a14f-90b63fd9af2d=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@5217f3d0}
14:05:78 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 22
14:05:78 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 22
14:05:78 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0
14:05:78 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:78 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:78 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:33 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 22
14:05:33 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-1
14:05:33 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:34 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-89d64236-8f83-4a2c-a14f-90b63fd9af2d sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:44 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
14:05:45 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-1=OffsetAndMetadata{offset=8, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:45 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
14:05:45 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-1
14:05:45 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:45 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:80 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:80 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:80 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-0
14:05:80 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:80 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-2
14:05:80 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 23: {consumer-MessageConsumer2-1-a9368041-4997-4e07-8ec4-3d8b3885feda=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@37ebc9d8, consumer-MessageConsumer2-1-8896c169-76bc-4348-a66b-240619301474=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@293bb8a5, consumer-MessageConsumer2-1-1f1976e6-9b25-4ce6-9032-624f6ff4fc68=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@2416a51}
14:05:81 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 23
14:05:81 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 23
14:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-1
14:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:57 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 23
14:05:57 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0
14:05:57 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:58 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-1f1976e6-9b25-4ce6-9032-624f6ff4fc68 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:69 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
14:05:69 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=7, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:69 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
14:05:69 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0
14:05:69 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:69 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:83 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:83 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:83 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-2
14:05:83 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:83 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-1
14:05:83 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:83 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 24: {consumer-MessageConsumer2-1-88e348a2-00d1-493e-bdd9-2b3de3f8176f=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6fa590ba, consumer-MessageConsumer2-1-a9368041-4997-4e07-8ec4-3d8b3885feda=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6e9319f, consumer-MessageConsumer2-1-8896c169-76bc-4348-a66b-240619301474=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@72e34f77}
14:05:83 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 24
14:05:83 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:83 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 24
14:05:83 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0
14:05:83 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:83 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:81 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 24
14:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-1
14:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:82 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-88e348a2-00d1-493e-bdd9-2b3de3f8176f sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:92 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
14:05:92 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-1=OffsetAndMetadata{offset=8, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:92 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
14:05:92 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-1
14:05:92 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:93 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:86 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:86 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:86 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-0
14:05:86 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-2
14:05:86 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:86 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:86 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 25: {consumer-MessageConsumer2-1-a9368041-4997-4e07-8ec4-3d8b3885feda=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@7bf9b098, consumer-MessageConsumer2-1-8896c169-76bc-4348-a66b-240619301474=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@389adf1d, consumer-MessageConsumer2-1-a378efd3-80af-4d34-83fc-8c0fd056461b=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@77307458}
14:05:86 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 25
14:05:86 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 25
14:05:86 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:86 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0
14:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:05 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 25
14:05:05 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-1
14:05:05 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:16 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-a378efd3-80af-4d34-83fc-8c0fd056461b sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:17 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
14:05:17 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-1=OffsetAndMetadata{offset=8, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:17 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
14:05:17 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-1
14:05:17 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:17 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:90 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:90 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:90 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-2
14:05:90 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:90 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-0
14:05:90 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:90 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 26: {consumer-MessageConsumer2-1-a9368041-4997-4e07-8ec4-3d8b3885feda=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@1fc0053e, consumer-MessageConsumer2-1-8896c169-76bc-4348-a66b-240619301474=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@290b1b2e, consumer-MessageConsumer2-1-cc5dbe34-49cb-4c00-bb9f-cd801c54bfaf=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@47874b25}
14:05:90 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 26
14:05:90 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-1
14:05:90 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 26
14:05:90 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0
14:05:90 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:91 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:29 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 26
14:05:29 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:30 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:31 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-cc5dbe34-49cb-4c00-bb9f-cd801c54bfaf sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:41 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
14:05:41 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-2=OffsetAndMetadata{offset=4, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:41 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
14:05:41 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-2
14:05:41 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:42 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:93 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:93 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-0
14:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-1
14:05:93 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:93 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 27: {consumer-MessageConsumer2-1-a9368041-4997-4e07-8ec4-3d8b3885feda=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@5db4c359, consumer-MessageConsumer2-1-8896c169-76bc-4348-a66b-240619301474=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@209775a9, consumer-MessageConsumer2-1-672de2dc-ca09-444b-8dd0-c65d975d2df9=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@18e7143f}
14:05:93 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 27
14:05:93 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 27
14:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-1
14:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:53 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 27
14:05:53 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0
14:05:53 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:54 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-672de2dc-ca09-444b-8dd0-c65d975d2df9 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:65 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
14:05:65 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=7, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:65 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
14:05:65 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0
14:05:65 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:65 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:96 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:96 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:96 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-2
14:05:96 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:96 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-1
14:05:96 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:96 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 28: {consumer-MessageConsumer2-1-a9368041-4997-4e07-8ec4-3d8b3885feda=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6fefce9e, consumer-MessageConsumer2-1-8896c169-76bc-4348-a66b-240619301474=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@4f8969b0, consumer-MessageConsumer2-1-af660b80-e038-4923-91fa-ff4877418965=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@1bdf8190}
14:05:96 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 28
14:05:96 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 28
14:05:96 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-1
14:05:96 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0
14:05:96 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:96 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:77 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 28
14:05:77 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:77 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:77 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-af660b80-e038-4923-91fa-ff4877418965 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:88 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
14:05:88 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-2=OffsetAndMetadata{offset=4, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:88 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
14:05:88 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-2
14:05:88 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:89 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:99 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:99 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-1
14:05:99 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-0
14:05:99 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 29: {consumer-MessageConsumer2-1-a9368041-4997-4e07-8ec4-3d8b3885feda=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@c65a5ef, consumer-MessageConsumer2-1-8896c169-76bc-4348-a66b-240619301474=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6b5176f2, consumer-MessageConsumer2-1-18887abe-a5ef-4155-891b-a3a51a33d6ba=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@b672aa8}
14:05:00 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 29
14:05:00 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 29
14:05:00 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:00 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-1
14:05:00 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:00 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:00 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 29
14:05:00 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0
14:05:00 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:04 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-18887abe-a5ef-4155-891b-a3a51a33d6ba sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:12 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
14:05:12 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=7, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:12 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
14:05:12 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0
14:05:12 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:12 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:02 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:02 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-1
14:05:02 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:04 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-2
14:05:04 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 30: {consumer-MessageConsumer2-1-a9368041-4997-4e07-8ec4-3d8b3885feda=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6e46d9f4, consumer-MessageConsumer2-1-8896c169-76bc-4348-a66b-240619301474=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@5cc69cfe, consumer-MessageConsumer2-1-a1587c72-048b-4cba-b28e-7a479f7615a6=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@29cfd92b}
14:05:04 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 30
14:05:04 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 30
14:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0
14:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:23 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 30
14:05:24 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-1
14:05:24 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:24 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-a1587c72-048b-4cba-b28e-7a479f7615a6 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:35 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
14:05:35 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-1=OffsetAndMetadata{offset=8, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:36 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
14:05:36 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-1
14:05:36 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:36 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:06 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:06 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:06 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-2
14:05:06 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:06 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-0
14:05:06 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:06 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 31: {consumer-MessageConsumer2-1-a9368041-4997-4e07-8ec4-3d8b3885feda=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@21c64522, consumer-MessageConsumer2-1-8896c169-76bc-4348-a66b-240619301474=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@7997b197, consumer-MessageConsumer2-1-662b6fb5-5cb1-47ce-87f1-74fef7b93cbf=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@11dee337}
14:05:07 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 31
14:05:07 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 31
14:05:07 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:07 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-1
14:05:07 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:07 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:47 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 31
14:05:47 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0
14:05:47 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:47 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-662b6fb5-5cb1-47ce-87f1-74fef7b93cbf sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:58 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
14:05:58 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=7, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:58 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
14:05:58 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0
14:05:58 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:58 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:10 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:10 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-1
14:05:10 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-2
14:05:10 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 32: {consumer-MessageConsumer2-1-a9368041-4997-4e07-8ec4-3d8b3885feda=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@460f76a6, consumer-MessageConsumer2-1-8896c169-76bc-4348-a66b-240619301474=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@55f3c410, consumer-MessageConsumer2-1-08a3188a-7ff9-4e00-9de0-c173cefe51a4=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@11acdc30}
14:05:10 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 32
14:05:10 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 32
14:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-1
14:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:70 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 32
14:05:70 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0
14:05:70 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:71 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-08a3188a-7ff9-4e00-9de0-c173cefe51a4 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:82 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
14:05:82 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=7, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:82 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
14:05:82 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0
14:05:82 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:82 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:12 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:12 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:12 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-2
14:05:12 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:12 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-1
14:05:12 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:13 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 33: {consumer-MessageConsumer2-1-a9368041-4997-4e07-8ec4-3d8b3885feda=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@770d4269, consumer-MessageConsumer2-1-8896c169-76bc-4348-a66b-240619301474=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@4a8ab068, consumer-MessageConsumer2-1-cc6da91f-f616-49cf-8853-f13c7ff7ed00=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@1922e6d}
14:05:13 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 33
14:05:13 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 33
14:05:13 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-1
14:05:13 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0
14:05:13 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:13 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:93 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 33
14:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:94 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-cc6da91f-f616-49cf-8853-f13c7ff7ed00 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:05 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
14:05:05 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-2=OffsetAndMetadata{offset=4, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:05 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
14:05:05 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-2
14:05:05 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:05 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:15 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:15 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:15 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-1
14:05:15 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:15 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-0
14:05:15 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:15 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 34: {consumer-MessageConsumer2-1-a9368041-4997-4e07-8ec4-3d8b3885feda=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@74bdc168, consumer-MessageConsumer2-1-8896c169-76bc-4348-a66b-240619301474=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@644c78d4, consumer-MessageConsumer2-1-53c68bfe-d681-4e42-935a-5b2ce78cbdd5=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@532a02d9}
14:05:15 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 34
14:05:15 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 34
14:05:15 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:15 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-1
14:05:15 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:15 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:17 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 34
14:05:17 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0
14:05:17 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:18 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-53c68bfe-d681-4e42-935a-5b2ce78cbdd5 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
14:05:28 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=7, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
14:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0
14:05:29 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:29 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:18 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:18 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:19 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-2
14:05:19 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:19 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-1
14:05:19 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:19 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 35: {consumer-MessageConsumer2-1-1058aad8-0b8b-48e1-af06-22c70b61ce7d=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@7cbee484, consumer-MessageConsumer2-1-a9368041-4997-4e07-8ec4-3d8b3885feda=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@7f811d00, consumer-MessageConsumer2-1-8896c169-76bc-4348-a66b-240619301474=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@62923ee6}
14:05:19 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 35
14:05:19 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 35
14:05:19 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:19 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-1
14:05:19 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:19 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:41 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 35
14:05:41 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0
14:05:41 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:43 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-1058aad8-0b8b-48e1-af06-22c70b61ce7d sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:52 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
14:05:52 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=7, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:52 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
14:05:52 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0
14:05:52 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:52 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:21 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:21 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:22 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-1
14:05:22 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:22 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-2
14:05:22 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:22 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 36: {consumer-MessageConsumer2-1-a9368041-4997-4e07-8ec4-3d8b3885feda=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@4089713, consumer-MessageConsumer2-1-8896c169-76bc-4348-a66b-240619301474=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@f19c9d2, consumer-MessageConsumer2-1-b6bc6eb5-2b2f-4913-b704-5eed82bc5027=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@7807ac2c}
14:05:22 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 36
14:05:22 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-1
14:05:22 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 36
14:05:22 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0
14:05:22 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:22 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:64 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 36
14:05:64 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:64 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:75 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-b6bc6eb5-2b2f-4913-b704-5eed82bc5027 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:76 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
14:05:76 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-2=OffsetAndMetadata{offset=4, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
14:05:76 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
14:05:76 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-2
14:05:76 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:76 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:25 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:25 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
14:05:25 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-1
14:05:25 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:26 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-0
14:05:26 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
14:05:26 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 37: {consumer-MessageConsumer2-1-a9368041-4997-4e07-8ec4-3d8b3885feda=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@a77614d, consumer-MessageConsumer2-1-8896c169-76bc-4348-a66b-240619301474=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@4fd4cae3, consumer-MessageConsumer2-1-85cf0ead-efba-42e4-b623-2ce11a294e1b=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@4a067c25}
14:05:26 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 37
14:05:26 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 37
14:05:26 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
14:05:26 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-1
14:05:26 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:26 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:87 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 37
14:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0
14:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
14:05:90 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-85cf0ead-efba-42e4-b623-2ce11a294e1b sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:07 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

15:05:33 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
15:05:33 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
15:05:33 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684757224330
15:05:33 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Subscribed to topic(s): test-topic-replicated
15:05:63 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
15:05:63 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
15:05:64 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:65 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:65 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 39: {consumer-MessageConsumer2-1-8ee97307-b7c4-443c-bfaa-7bb18d4f4568=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@63648ee9}
15:05:65 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 39
15:05:66 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:67 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:67 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:67 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:02 [main] INFO  producer.MessageProducer - Selected Option is : 1 
15:05:08 [main] INFO  producer.MessageProducer - Entered message is abc
15:05:11 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

15:05:34 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
15:05:34 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
15:05:34 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684757256341
15:05:40 [kafka-producer-network-thread | producer-1] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
15:05:67 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
15:05:70 [main] INFO  producer.MessageProducer - Message abc sent successfully for the key null
15:05:70 [main] INFO  producer.MessageProducer - Published message Offset is 4 and the partition is 2
15:05:70 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
15:05:11 [main] INFO  c.MessageConsumerSynchronousCommit - Consumer Record key is null and the value is abc and the partition is 2
15:05:19 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

15:05:45 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
15:05:45 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
15:05:45 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684757309451
15:05:45 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Subscribed to topic(s): test-topic-replicated
15:05:64 [main] INFO  producer.MessageProducer - Entered message is hahaha
15:05:64 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

15:05:65 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
15:05:65 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
15:05:65 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684757314655
15:05:70 [kafka-producer-network-thread | producer-2] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-2] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
15:05:71 [kafka-producer-network-thread | producer-2] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
15:05:71 [main] INFO  producer.MessageProducer - Message hahaha sent successfully for the key null
15:05:71 [main] INFO  producer.MessageProducer - Published message Offset is 8 and the partition is 1
15:05:71 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
15:05:75 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
15:05:76 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
15:05:76 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:77 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:77 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 41: {consumer-MessageConsumer2-1-4ac52728-39b1-4d6f-82a8-a503b2a1c9c9=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@63648ee9}
15:05:77 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 41
15:05:78 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:79 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:79 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:79 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:84 [main] INFO  c.MessageConsumerSynchronousCommit - Consumer Record key is null and the value is hahaha and the partition is 1
15:05:84 [main] INFO  c.MessageConsumerSynchronousCommit - Offset is committed
15:05:02 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

15:05:27 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
15:05:27 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
15:05:27 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684758133273
15:05:28 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Subscribed to topic(s): test-topic-replicated
15:05:57 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
15:05:57 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
15:05:57 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:58 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:47 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Attempt to heartbeat failed since group is rebalancing
15:05:47 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Revoke previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:47 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:47 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 42: {consumer-MessageConsumer2-1-7eb64f41-c3ad-46ce-b4ec-645be787f2eb=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6b5176f2, consumer-MessageConsumer2-1-4ac52728-39b1-4d6f-82a8-a503b2a1c9c9=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@b672aa8}
15:05:47 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 42
15:05:47 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1
15:05:47 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:47 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:68 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 42
15:05:69 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-2
15:05:70 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:32 [main] INFO  producer.MessageProducer - Selected Option is : 1 
15:05:34 [main] INFO  producer.MessageProducer - Entered message is hahahahaha
15:05:37 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

15:05:60 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
15:05:60 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
15:05:60 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684758164602
15:05:87 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
15:05:91 [main] INFO  producer.MessageProducer - Message hahahahaha sent successfully for the key null
15:05:91 [main] INFO  producer.MessageProducer - Published message Offset is 5 and the partition is 2
15:05:91 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
15:05:08 [main] INFO  c.MessageConsumerASynchronousCommit - Consumer Record key is null and the value is hahahahaha and the partition is 2
15:05:08 [main] INFO  c.MessageConsumerASynchronousCommit - Offset is committed
15:05:11 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

15:05:38 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
15:05:38 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
15:05:38 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684759161378
15:05:38 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Subscribed to topic(s): test-topic-replicated
15:05:64 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
15:05:64 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
15:05:65 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:66 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:66 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 44: {consumer-MessageConsumer2-1-8f1c2679-ddd6-4651-ab93-7c914e583037=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@63648ee9}
15:05:66 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 44
15:05:67 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:68 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:68 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:68 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:65 [main] INFO  producer.MessageProducer - Selected Option is : 1 
15:05:67 [main] INFO  producer.MessageProducer - Entered message is heyo
15:05:70 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

15:05:93 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
15:05:93 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
15:05:93 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684759171931
15:05:20 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
15:05:24 [main] INFO  producer.MessageProducer - Message heyo sent successfully for the key null
15:05:24 [main] INFO  producer.MessageProducer - Published message Offset is 7 and the partition is 0
15:05:24 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
15:05:25 [main] INFO  c.MessageConsumerCommitSpecificOffset - Consumer Record key is null and the value is heyo and the partition is 0
15:05:25 [main] INFO  c.MessageConsumerCommitSpecificOffset - Offset is committed
15:05:24 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 5000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

15:05:50 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
15:05:50 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
15:05:50 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684759516503
15:05:51 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Subscribed to topic(s): test-topic-replicated
15:05:78 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
15:05:78 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
15:05:79 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:79 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:80 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 46: {consumer-MessageConsumer2-1-9abef749-60ae-4ecd-9899-29d315b50c76=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@7651218e}
15:05:80 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 46
15:05:80 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:80 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:82 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:84 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-9abef749-60ae-4ecd-9899-29d315b50c76 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:89 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:89 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:89 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:89 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:89 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:89 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:89 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:89 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 48: {consumer-MessageConsumer2-1-8fb31c90-3ab8-43d9-a943-1791270038b9=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@69c79f09}
15:05:89 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 48
15:05:89 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:89 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:89 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:89 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:89 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:90 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-8fb31c90-3ab8-43d9-a943-1791270038b9 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:01 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:01 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:01 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:01 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:01 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:01 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:01 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:01 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 50: {consumer-MessageConsumer2-1-b5e41af5-1ba8-497a-831d-31f68edbf4d9=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6a988392}
15:05:01 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 50
15:05:01 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:01 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:01 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:01 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:01 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:05 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-b5e41af5-1ba8-497a-831d-31f68edbf4d9 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:13 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:13 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:13 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:13 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:13 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:13 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:13 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:13 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 52: {consumer-MessageConsumer2-1-6be531a8-a9c4-4dff-99c6-20184b225470=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@1d71006f}
15:05:13 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 52
15:05:13 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:13 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:13 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:13 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:13 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:21 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 5000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

15:05:47 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
15:05:47 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
15:05:47 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684759563471
15:05:47 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Subscribed to topic(s): test-topic-replicated
15:05:76 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
15:05:76 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
15:05:76 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:77 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:78 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 54: {consumer-MessageConsumer2-1-263637d0-8709-4d4a-b102-af679be0d380=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@7651218e}
15:05:78 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 54
15:05:78 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:78 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:79 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:79 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:79 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:91 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-263637d0-8709-4d4a-b102-af679be0d380 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:86 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:86 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:86 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:86 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:86 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:86 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:86 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:86 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 56: {consumer-MessageConsumer2-1-17775cf4-2636-488b-b214-17c4e204f513=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@69c79f09}
15:05:86 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 56
15:05:86 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:86 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:86 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:89 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-17775cf4-2636-488b-b214-17c4e204f513 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:97 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:97 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:97 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:97 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:97 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:97 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:98 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 58: {consumer-MessageConsumer2-1-1b8f7fa7-32c4-4da7-96dd-0e5e90f0ec74=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6a988392}
15:05:98 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 58
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:98 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:00 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-1b8f7fa7-32c4-4da7-96dd-0e5e90f0ec74 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:09 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:09 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:09 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:09 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:09 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:09 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:09 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:09 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 60: {consumer-MessageConsumer2-1-1fc34211-1cee-4773-b815-0c4ad7418d5d=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@1d71006f}
15:05:09 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 60
15:05:09 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:09 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:09 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:09 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:09 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:11 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-1fc34211-1cee-4773-b815-0c4ad7418d5d sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:21 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:21 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:21 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:21 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:21 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:21 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:21 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:21 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 62: {consumer-MessageConsumer2-1-ec60c8d7-0721-470b-b1df-cd1c95b06873=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@5b6813df}
15:05:21 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 62
15:05:21 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:21 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:21 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:21 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:21 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:26 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-ec60c8d7-0721-470b-b1df-cd1c95b06873 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:32 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:32 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:32 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:32 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:32 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:32 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:32 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:32 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 64: {consumer-MessageConsumer2-1-b9807e18-9311-4a4b-98a7-a8533d3cbcb0=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@5f2606b}
15:05:32 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 64
15:05:32 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:32 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:32 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:32 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:32 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:34 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-b9807e18-9311-4a4b-98a7-a8533d3cbcb0 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:43 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:43 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:43 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:43 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:43 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:43 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:43 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:43 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 66: {consumer-MessageConsumer2-1-adf83fa1-348d-4b78-b1bc-7908c36ce509=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@2b58f754}
15:05:43 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 66
15:05:43 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:43 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:44 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:44 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:44 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:46 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-adf83fa1-348d-4b78-b1bc-7908c36ce509 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:55 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:55 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:55 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:55 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:55 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:55 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:55 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:55 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 68: {consumer-MessageConsumer2-1-85870cec-be06-45ea-85ca-a030ef9522a6=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@3ebff828}
15:05:56 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 68
15:05:56 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:56 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:56 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:56 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:56 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:57 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-85870cec-be06-45ea-85ca-a030ef9522a6 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:66 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:66 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:66 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:66 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:66 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:66 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:66 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:67 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 70: {consumer-MessageConsumer2-1-a91ec267-2695-4060-b518-828b9e354fc6=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@2552f2cb}
15:05:67 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 70
15:05:67 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:67 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:67 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:67 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:67 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:69 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-a91ec267-2695-4060-b518-828b9e354fc6 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:78 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:78 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:78 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:78 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:78 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:78 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:78 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:78 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 72: {consumer-MessageConsumer2-1-31b0f4d6-99b8-4836-b1bf-9ad3e51e7886=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@33352f32}
15:05:79 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 72
15:05:79 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:79 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:79 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:79 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:79 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:80 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-31b0f4d6-99b8-4836-b1bf-9ad3e51e7886 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:89 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:89 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:89 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:89 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:89 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:89 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:90 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:90 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 74: {consumer-MessageConsumer2-1-f7f394ec-fa7c-42e8-8f80-5fab5a6fca1d=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@5f3b9c57}
15:05:90 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 74
15:05:90 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:90 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:90 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:90 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:90 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:92 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-f7f394ec-fa7c-42e8-8f80-5fab5a6fca1d sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:01 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:01 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:01 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:01 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:01 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:01 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:01 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:02 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 76: {consumer-MessageConsumer2-1-7a28adbe-0e24-45cf-b49d-3af89310f36e=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@1e044120}
15:05:02 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 76
15:05:02 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:02 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:02 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:02 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:02 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:04 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-7a28adbe-0e24-45cf-b49d-3af89310f36e sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:13 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:13 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:13 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:13 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:13 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:13 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:13 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:13 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 78: {consumer-MessageConsumer2-1-e70980db-5e99-4dd3-b1a5-0a2538917fa3=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@2cf23c81}
15:05:14 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 78
15:05:14 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:14 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:14 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:14 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:14 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:16 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-e70980db-5e99-4dd3-b1a5-0a2538917fa3 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:25 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:25 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:25 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:25 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:25 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:25 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:25 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:25 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 80: {consumer-MessageConsumer2-1-449cfd38-a94d-41f6-8d66-dc8cd40ae5a4=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@3624da92}
15:05:26 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 80
15:05:26 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:26 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:26 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:26 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:26 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:27 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-449cfd38-a94d-41f6-8d66-dc8cd40ae5a4 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:36 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:36 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:36 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:36 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:36 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:36 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:37 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:37 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 82: {consumer-MessageConsumer2-1-0b726a4b-b2b6-4a22-8490-223f03d2d2a9=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@35fe2125}
15:05:37 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 82
15:05:37 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:37 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:37 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:37 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:37 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:38 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-0b726a4b-b2b6-4a22-8490-223f03d2d2a9 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:49 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:49 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:49 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:49 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:49 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:49 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:49 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:49 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 84: {consumer-MessageConsumer2-1-54665a67-e805-4567-8e95-d442b8ea4fed=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@94f6bfb}
15:05:49 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 84
15:05:49 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:49 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:50 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:50 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:50 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:50 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-54665a67-e805-4567-8e95-d442b8ea4fed sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:61 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:61 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:61 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:61 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:61 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:61 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:61 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:61 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 86: {consumer-MessageConsumer2-1-50ead0a9-2444-4935-828a-d45bb4839dde=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@34645867}
15:05:62 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 86
15:05:62 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:62 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:62 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:62 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:62 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:62 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-50ead0a9-2444-4935-828a-d45bb4839dde sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:73 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:73 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:73 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:73 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:73 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:73 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:73 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:74 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 88: {consumer-MessageConsumer2-1-66a48c97-dcf8-49a7-9b41-22265b116fb8=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@2484f433}
15:05:74 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 88
15:05:74 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:74 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:74 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:74 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:74 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:75 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-66a48c97-dcf8-49a7-9b41-22265b116fb8 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:84 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:84 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:84 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:84 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:84 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:84 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:84 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:84 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 90: {consumer-MessageConsumer2-1-35d2159f-0876-4e26-b4c3-03c656c2ece9=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@60b71e8f}
15:05:85 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 90
15:05:85 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:85 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:85 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:85 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:85 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:95 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-35d2159f-0876-4e26-b4c3-03c656c2ece9 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:95 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:95 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:95 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:95 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:95 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:95 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:95 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:96 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 92: {consumer-MessageConsumer2-1-5ca3c073-9729-4a65-adf5-783383f62387=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@1255b1d1}
15:05:96 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 92
15:05:96 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:96 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:96 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:96 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:96 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:98 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-5ca3c073-9729-4a65-adf5-783383f62387 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:07 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:07 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:07 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:07 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:07 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:07 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:07 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:07 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 94: {consumer-MessageConsumer2-1-ac228a9d-9b83-4cf8-b171-c63c046516e8=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@464649c}
15:05:08 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 94
15:05:08 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:08 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:08 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:08 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:08 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:10 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-ac228a9d-9b83-4cf8-b171-c63c046516e8 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:18 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:18 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:18 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:18 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:18 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:18 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:18 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:18 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 96: {consumer-MessageConsumer2-1-00cfc713-fa2c-4ac3-97d8-c2f1bec0a091=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@7c22d4f}
15:05:19 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 96
15:05:19 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:19 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:19 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:19 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:19 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:20 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-00cfc713-fa2c-4ac3-97d8-c2f1bec0a091 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:31 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:31 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:31 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:31 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:31 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:31 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:31 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:31 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 98: {consumer-MessageConsumer2-1-bd1db152-1911-40a3-b9e8-fe4293a4a67a=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@5f59185e}
15:05:31 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 98
15:05:31 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:31 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:31 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:31 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:31 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:32 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-bd1db152-1911-40a3-b9e8-fe4293a4a67a sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:42 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:42 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:42 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:42 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:42 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:42 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:42 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:42 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 100: {consumer-MessageConsumer2-1-e311da93-0fe1-4236-a9de-52594b12cde9=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@60bdf15d}
15:05:42 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 100
15:05:42 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:42 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:42 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:42 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:42 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:44 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-e311da93-0fe1-4236-a9de-52594b12cde9 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:53 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:53 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:53 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:53 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:53 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:53 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:53 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:53 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 102: {consumer-MessageConsumer2-1-6df84568-cb42-49dd-96c8-8c8e54fcd4b5=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@47da3952}
15:05:53 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 102
15:05:53 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:54 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:54 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:54 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:54 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:55 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-6df84568-cb42-49dd-96c8-8c8e54fcd4b5 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:64 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:64 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:64 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:64 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:64 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:64 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:64 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:65 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 104: {consumer-MessageConsumer2-1-e040f4a7-05f0-4852-bdee-b61ba2f3ea96=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@51e4ccb3}
15:05:65 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 104
15:05:65 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:65 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:65 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:65 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:65 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:66 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-e040f4a7-05f0-4852-bdee-b61ba2f3ea96 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:75 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:75 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:75 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:75 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:75 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:75 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:75 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:76 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 106: {consumer-MessageConsumer2-1-f2e074a4-cd3c-44ea-8961-bc47dc580d4c=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@46e8a539}
15:05:76 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 106
15:05:76 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:76 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:76 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:76 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:76 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:78 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-f2e074a4-cd3c-44ea-8961-bc47dc580d4c sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:87 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:87 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:87 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:87 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 108: {consumer-MessageConsumer2-1-f22d4379-761b-499a-88b1-9acb11aa3332=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@495083a0}
15:05:87 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 108
15:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:87 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:89 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-f22d4379-761b-499a-88b1-9acb11aa3332 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:98 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:98 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:98 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:99 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 110: {consumer-MessageConsumer2-1-89e590bc-0d55-4cef-8413-9888e8b6a6fc=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@5fd62371}
15:05:99 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 110
15:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:99 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:01 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-89e590bc-0d55-4cef-8413-9888e8b6a6fc sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:10 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:10 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:10 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:10 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:11 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 112: {consumer-MessageConsumer2-1-772eeb51-e4e9-4b7a-8ad8-aec9072b3f84=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@28a0fd6c}
15:05:11 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 112
15:05:11 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:11 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:11 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:11 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:11 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:12 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-772eeb51-e4e9-4b7a-8ad8-aec9072b3f84 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:21 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:21 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:21 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:21 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:21 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:21 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:21 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:22 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 114: {consumer-MessageConsumer2-1-5a2e9c0b-9667-4f57-85e4-d02b5e2c5bfb=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@2b62442c}
15:05:22 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 114
15:05:22 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:22 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:22 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:22 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:22 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:24 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-5a2e9c0b-9667-4f57-85e4-d02b5e2c5bfb sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:32 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:32 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:32 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:32 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:32 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:32 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:32 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:33 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 116: {consumer-MessageConsumer2-1-53a75369-f05d-4ee0-a4a3-8a00b2ce8175=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@66629f63}
15:05:33 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 116
15:05:33 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:33 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:33 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:33 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:33 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:36 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-53a75369-f05d-4ee0-a4a3-8a00b2ce8175 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:45 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:45 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:45 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:45 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:45 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:45 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:45 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:45 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 118: {consumer-MessageConsumer2-1-7717b9a8-b0b5-43ee-a85e-e9c00b87379d=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@841e575}
15:05:45 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 118
15:05:45 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:45 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:45 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:45 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:45 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:47 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-7717b9a8-b0b5-43ee-a85e-e9c00b87379d sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:56 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:56 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:56 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:56 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:56 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:56 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:56 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:56 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 120: {consumer-MessageConsumer2-1-b3285079-8d69-464e-8ca2-7eb9494ed780=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@27a5328c}
15:05:56 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 120
15:05:56 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:56 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:56 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:56 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:56 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:57 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-b3285079-8d69-464e-8ca2-7eb9494ed780 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:67 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:67 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:67 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:68 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:68 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:68 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:68 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:68 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 122: {consumer-MessageConsumer2-1-14a77c05-c776-45a5-b697-9341631ce651=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@1e5f4170}
15:05:68 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 122
15:05:68 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:68 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:68 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:68 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:68 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:71 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-14a77c05-c776-45a5-b697-9341631ce651 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:80 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:80 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:80 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:80 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:80 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:80 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:80 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:80 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 124: {consumer-MessageConsumer2-1-01decd73-a83e-43c3-8e71-7fd36505e799=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6c345c5f}
15:05:80 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 124
15:05:80 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:80 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:80 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:80 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:80 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:84 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-01decd73-a83e-43c3-8e71-7fd36505e799 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:92 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:92 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:92 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:92 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:92 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:92 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:92 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:92 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 126: {consumer-MessageConsumer2-1-c0c21167-365c-4552-b200-2ebdc878c7ba=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6b5966e1}
15:05:92 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 126
15:05:92 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:92 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:96 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-c0c21167-365c-4552-b200-2ebdc878c7ba sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:04 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:04 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:04 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:04 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 128: {consumer-MessageConsumer2-1-d74d82ed-9ce6-4f5f-b3a7-344e77c86842=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@65e61854}
15:05:04 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 128
15:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:04 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:05 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-d74d82ed-9ce6-4f5f-b3a7-344e77c86842 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:16 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:16 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:16 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:16 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:16 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:16 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:16 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:17 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 130: {consumer-MessageConsumer2-1-37ddd7a3-752e-474a-8b34-e1878d07f20e=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@1568159}
15:05:17 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 130
15:05:17 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:17 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:17 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:17 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:17 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:17 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-37ddd7a3-752e-474a-8b34-e1878d07f20e sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:28 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:28 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:28 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:28 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 132: {consumer-MessageConsumer2-1-c99d70a8-de1b-4631-8d0d-2a0c652a226a=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@4fcee388}
15:05:28 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 132
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:28 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:29 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:29 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:29 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:30 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-c99d70a8-de1b-4631-8d0d-2a0c652a226a sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:40 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:40 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:40 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:40 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 134: {consumer-MessageConsumer2-1-0b7a0102-5487-413a-9935-de188011e527=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6f80fafe}
15:05:40 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 134
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:40 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:42 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-0b7a0102-5487-413a-9935-de188011e527 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:52 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:52 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:52 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:52 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:52 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:52 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:52 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:52 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 136: {consumer-MessageConsumer2-1-b19b57ec-bf46-42ab-af75-221176b0c90b=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@3af17be2}
15:05:52 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 136
15:05:52 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:52 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:52 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:52 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:52 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:54 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-b19b57ec-bf46-42ab-af75-221176b0c90b sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:64 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:64 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:64 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:64 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:64 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:64 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:64 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:64 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 138: {consumer-MessageConsumer2-1-0bede18b-010e-40f9-b6e8-a65108088d6d=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@f9879ac}
15:05:64 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 138
15:05:64 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:64 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:64 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:64 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:64 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:67 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-0bede18b-010e-40f9-b6e8-a65108088d6d sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:76 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:76 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:76 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:76 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:76 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:76 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:76 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:76 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 140: {consumer-MessageConsumer2-1-e57a637d-26b5-45d5-894a-fcc8e0eac408=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@37f21974}
15:05:76 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 140
15:05:77 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:77 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:77 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:77 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:77 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:77 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-e57a637d-26b5-45d5-894a-fcc8e0eac408 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:87 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:87 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:87 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:87 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 142: {consumer-MessageConsumer2-1-db9d70c1-c95f-44de-84cd-86aacdd2e1cb=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@5f4d427e}
15:05:87 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 142
15:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:87 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:89 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-db9d70c1-c95f-44de-84cd-86aacdd2e1cb sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:98 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:98 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:98 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:98 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 144: {consumer-MessageConsumer2-1-b523cb77-fbb1-4eb6-a40a-09fdff85b45e=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6e521c1e}
15:05:98 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 144
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:98 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:01 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-b523cb77-fbb1-4eb6-a40a-09fdff85b45e sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:10 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:10 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:10 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:10 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 146: {consumer-MessageConsumer2-1-4032ca08-956e-4810-b650-95b7bd79a70c=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@224b4d61}
15:05:10 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 146
15:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:10 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:12 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-4032ca08-956e-4810-b650-95b7bd79a70c sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:21 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:21 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:21 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:21 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:21 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:21 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:21 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:22 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 148: {consumer-MessageConsumer2-1-bde3e9b2-0e09-46d6-8f3c-17e33ae36807=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@5d5d9e5}
15:05:22 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 148
15:05:22 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:22 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:22 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:22 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:22 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:24 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-bde3e9b2-0e09-46d6-8f3c-17e33ae36807 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:33 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:33 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:33 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:33 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:33 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:33 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:33 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:33 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 150: {consumer-MessageConsumer2-1-1bca6f1e-db4f-429d-a31d-0cf68f36137f=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@303e3593}
15:05:33 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 150
15:05:33 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:33 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:33 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:33 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:33 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:36 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-1bca6f1e-db4f-429d-a31d-0cf68f36137f sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:44 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:44 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:44 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:44 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:44 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:44 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:44 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:44 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 152: {consumer-MessageConsumer2-1-e803b96b-a70d-48e2-ac08-62748f32c331=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@4ef27d66}
15:05:44 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 152
15:05:44 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:44 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:44 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:44 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:44 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:45 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-e803b96b-a70d-48e2-ac08-62748f32c331 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:55 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:55 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:55 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:55 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:55 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:55 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:55 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:55 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 154: {consumer-MessageConsumer2-1-f4ae93f2-8fa7-4e36-b208-e629eda10a41=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@362a019c}
15:05:55 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 154
15:05:55 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:55 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:55 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:55 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:55 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:58 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-f4ae93f2-8fa7-4e36-b208-e629eda10a41 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:66 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:66 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:66 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:66 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:66 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:66 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:67 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:67 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 156: {consumer-MessageConsumer2-1-f72e65cc-5e33-4287-8cad-303b2b5a225a=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@1d9bec4d}
15:05:67 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 156
15:05:67 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:67 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:67 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:67 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:67 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:68 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-f72e65cc-5e33-4287-8cad-303b2b5a225a sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:78 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:78 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:78 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:78 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:78 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:78 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:78 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:78 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 158: {consumer-MessageConsumer2-1-181271c7-55a1-4e82-8734-c5ec02949ab9=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@5c48c0c0}
15:05:78 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 158
15:05:78 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:78 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:78 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:78 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:78 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:80 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-181271c7-55a1-4e82-8734-c5ec02949ab9 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:90 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:90 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:90 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:90 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:90 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:90 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:90 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:90 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 160: {consumer-MessageConsumer2-1-c6f22f75-1b98-4337-bf53-70ae14b649fb=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@10c8f62}
15:05:90 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 160
15:05:90 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:90 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:90 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:90 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:90 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:92 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-c6f22f75-1b98-4337-bf53-70ae14b649fb sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:01 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:01 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:01 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:01 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:01 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:01 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:01 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:01 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 162: {consumer-MessageConsumer2-1-825a14e2-5ffd-452e-963b-7243c135f475=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@674c583e}
15:05:01 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 162
15:05:01 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:01 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:01 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:01 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:01 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:03 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-825a14e2-5ffd-452e-963b-7243c135f475 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:12 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:12 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:12 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:12 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:12 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:12 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:12 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:12 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 164: {consumer-MessageConsumer2-1-7a631d4e-0838-402c-ae44-4ba6ecb36f99=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@25f7391e}
15:05:12 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 164
15:05:12 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:12 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:12 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:12 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:12 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:15 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-7a631d4e-0838-402c-ae44-4ba6ecb36f99 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:24 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:24 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:24 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:24 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:24 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:24 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:24 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:24 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 166: {consumer-MessageConsumer2-1-ede4e367-d7b7-461f-84a5-9a446e357f40=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@3f23a3a0}
15:05:24 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 166
15:05:24 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:24 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:24 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:24 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:24 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:27 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-ede4e367-d7b7-461f-84a5-9a446e357f40 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:35 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:35 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:35 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:35 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:35 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:35 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:36 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:36 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 168: {consumer-MessageConsumer2-1-eae32ec0-1094-4e0d-a991-0b2067358ee6=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@5ab14cb9}
15:05:36 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 168
15:05:36 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:36 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:36 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:36 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:36 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:38 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-eae32ec0-1094-4e0d-a991-0b2067358ee6 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:48 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:48 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:48 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:48 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:48 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:48 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:48 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:48 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 170: {consumer-MessageConsumer2-1-1a3dff44-6645-4194-9053-8d100d51617d=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@5fb97279}
15:05:48 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 170
15:05:48 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:48 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:48 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:48 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:48 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:50 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-1a3dff44-6645-4194-9053-8d100d51617d sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:59 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:59 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:59 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:59 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:59 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:60 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:60 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:60 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 172: {consumer-MessageConsumer2-1-c752d76d-150d-4fa6-ba22-c9005c7f3679=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@439a8f59}
15:05:60 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 172
15:05:60 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:60 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:60 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:60 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:60 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:62 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-c752d76d-150d-4fa6-ba22-c9005c7f3679 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:71 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:71 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:71 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:71 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:71 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:71 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:71 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:71 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 174: {consumer-MessageConsumer2-1-88108a31-77b5-4164-bc9d-e9f00568ad3f=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@61861a29}
15:05:71 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 174
15:05:71 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:72 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:72 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:72 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:72 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:73 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-88108a31-77b5-4164-bc9d-e9f00568ad3f sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:82 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:82 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:82 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:82 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:82 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:82 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:82 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:82 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 176: {consumer-MessageConsumer2-1-255e3002-480d-402a-95da-1694de786b52=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@31024624}
15:05:82 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 176
15:05:82 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:82 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:82 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:82 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:82 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:84 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-255e3002-480d-402a-95da-1694de786b52 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:93 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:93 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:93 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:94 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:94 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 178: {consumer-MessageConsumer2-1-effd4ba7-a0f4-4294-93a9-d65f378d29a7=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@25bcd0c7}
15:05:94 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 178
15:05:94 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:94 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:94 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:94 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:94 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:96 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-effd4ba7-a0f4-4294-93a9-d65f378d29a7 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:05 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:05 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:05 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:05 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:05 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:05 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:05 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:05 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 180: {consumer-MessageConsumer2-1-97687f67-2ef7-4a77-8ed2-b75659a2e729=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@32cb636e}
15:05:06 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 180
15:05:06 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:06 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:06 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:06 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:06 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:07 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-97687f67-2ef7-4a77-8ed2-b75659a2e729 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:17 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:17 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:17 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:17 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:17 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:17 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:17 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:17 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 182: {consumer-MessageConsumer2-1-f002e14f-0e0a-4a54-b01c-25a358061c51=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@63cd604c}
15:05:17 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 182
15:05:17 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:17 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:17 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:17 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:17 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:20 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-f002e14f-0e0a-4a54-b01c-25a358061c51 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:28 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:28 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:28 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:28 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 184: {consumer-MessageConsumer2-1-6a7daad2-99bd-4d44-94b3-66d90e15c2c6=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@40dd3977}
15:05:28 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 184
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:28 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:30 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-6a7daad2-99bd-4d44-94b3-66d90e15c2c6 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:40 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:40 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:40 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:40 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 186: {consumer-MessageConsumer2-1-14e81891-6022-48a5-a07b-0a97f49f3110=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@3a4e343}
15:05:40 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 186
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:40 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:43 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-14e81891-6022-48a5-a07b-0a97f49f3110 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:52 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:52 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:52 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:52 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:52 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:52 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:52 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:52 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 188: {consumer-MessageConsumer2-1-0c0cbde9-aaba-4a35-a8ff-20163489a6aa=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6a1d204a}
15:05:52 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 188
15:05:52 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:52 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:52 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:52 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:52 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:54 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-0c0cbde9-aaba-4a35-a8ff-20163489a6aa sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:63 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:63 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:63 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:63 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:63 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:63 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:63 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:63 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 190: {consumer-MessageConsumer2-1-763a2f3f-aae3-4ddd-be76-e658df569371=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@62dae245}
15:05:63 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 190
15:05:63 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:63 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:63 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:63 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:63 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:65 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-763a2f3f-aae3-4ddd-be76-e658df569371 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:74 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:74 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:74 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:74 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:74 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:74 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:75 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:75 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 192: {consumer-MessageConsumer2-1-36b04dd7-22e1-46b0-8784-95a6faef4d60=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@4b6579e8}
15:05:75 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 192
15:05:75 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:75 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:75 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:75 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:75 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:77 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-36b04dd7-22e1-46b0-8784-95a6faef4d60 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:86 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:86 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:86 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:86 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:86 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:86 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:86 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 194: {consumer-MessageConsumer2-1-0e30186f-70c1-41b0-9b7e-dd6991460535=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6fff253c}
15:05:87 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 194
15:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:87 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:89 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-0e30186f-70c1-41b0-9b7e-dd6991460535 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:98 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:98 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:98 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:99 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 196: {consumer-MessageConsumer2-1-a9a104ea-2a95-4285-ae25-a9f21a76cad2=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6c6357f9}
15:05:99 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 196
15:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:99 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:01 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-a9a104ea-2a95-4285-ae25-a9f21a76cad2 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:10 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:10 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:10 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:10 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 198: {consumer-MessageConsumer2-1-98a18500-d720-467c-87d9-e27e47de8432=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@591e58fa}
15:05:10 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 198
15:05:11 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:11 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:11 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:11 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:11 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:13 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-98a18500-d720-467c-87d9-e27e47de8432 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:22 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:22 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:22 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:22 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:22 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:22 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:23 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:23 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 200: {consumer-MessageConsumer2-1-db5aee10-44c8-4bcf-bb16-e179fa711c56=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@3954d008}
15:05:23 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 200
15:05:23 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:23 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:23 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:23 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:23 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:24 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-db5aee10-44c8-4bcf-bb16-e179fa711c56 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:34 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:34 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:34 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:34 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:34 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:34 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:34 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:34 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 202: {consumer-MessageConsumer2-1-06a74d08-970a-4e26-a678-287786a6eee9=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@2f94c4db}
15:05:34 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 202
15:05:34 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:34 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:34 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:34 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:34 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:36 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-06a74d08-970a-4e26-a678-287786a6eee9 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:45 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:45 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:45 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:45 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:45 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:45 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:45 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:45 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 204: {consumer-MessageConsumer2-1-7415498b-66df-4980-8d1a-658d0243df09=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@593e824f}
15:05:45 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 204
15:05:45 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:45 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:45 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:45 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:45 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:47 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-7415498b-66df-4980-8d1a-658d0243df09 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:57 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:57 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:57 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:57 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:57 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:57 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:57 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:57 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 206: {consumer-MessageConsumer2-1-65266438-bd5f-4996-8af2-d243905e730e=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@72ccd81a}
15:05:57 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 206
15:05:57 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:57 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:57 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:57 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:57 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:62 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-65266438-bd5f-4996-8af2-d243905e730e sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:68 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:68 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:68 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:68 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:68 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:68 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:68 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:69 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 208: {consumer-MessageConsumer2-1-c5fc7f29-74c4-4790-9ac1-f7fb6d6ce6fa=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6d8792db}
15:05:69 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 208
15:05:69 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:69 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:69 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:69 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:69 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:73 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-c5fc7f29-74c4-4790-9ac1-f7fb6d6ce6fa sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:81 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:81 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:81 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:81 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 210: {consumer-MessageConsumer2-1-11ecc372-54b7-4fc4-a07d-6228794fe324=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@64bc21ac}
15:05:81 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 210
15:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:81 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:85 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-11ecc372-54b7-4fc4-a07d-6228794fe324 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:92 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:92 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:92 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:92 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:92 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:92 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:92 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 212: {consumer-MessageConsumer2-1-d7a26ede-88e5-40dd-817f-fb8e9f90436f=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@493dfb8e}
15:05:93 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 212
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:93 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:96 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-d7a26ede-88e5-40dd-817f-fb8e9f90436f sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:04 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:04 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:04 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:04 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 214: {consumer-MessageConsumer2-1-8aee2dd1-51f8-4083-ac1f-e29042d6c4c6=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@5d25e6bb}
15:05:04 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 214
15:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:04 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:07 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-8aee2dd1-51f8-4083-ac1f-e29042d6c4c6 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:15 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:15 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:15 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:15 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:15 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:15 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:15 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:15 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 216: {consumer-MessageConsumer2-1-41a8e728-962d-455a-a32b-6cf469bb7c69=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@ce5a68e}
15:05:16 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 216
15:05:16 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:16 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:16 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:16 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:16 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:17 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-41a8e728-962d-455a-a32b-6cf469bb7c69 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:28 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:28 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:28 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:28 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 218: {consumer-MessageConsumer2-1-6b0d11fa-f11f-437e-b438-993d9d8d4e1a=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@9d157ff}
15:05:28 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 218
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:28 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:29 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-6b0d11fa-f11f-437e-b438-993d9d8d4e1a sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:40 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:40 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:40 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:40 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 220: {consumer-MessageConsumer2-1-91cec36a-ee04-4ca8-a3a2-d482566a69e9=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@2f162cc0}
15:05:40 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 220
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:40 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:44 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-91cec36a-ee04-4ca8-a3a2-d482566a69e9 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:51 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:51 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:51 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:51 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:51 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:51 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:51 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:51 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 222: {consumer-MessageConsumer2-1-b20c5247-e24b-4332-9f59-c3f974b06a29=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@5df417a7}
15:05:51 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 222
15:05:51 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:51 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:51 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:51 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:51 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:55 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-b20c5247-e24b-4332-9f59-c3f974b06a29 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:63 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:63 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:63 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:63 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:63 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:63 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:63 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:63 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 224: {consumer-MessageConsumer2-1-d9427502-d7cc-4505-8bcb-401766214b5f=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@7c041b41}
15:05:63 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 224
15:05:63 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:63 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:63 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:63 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:63 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:67 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-d9427502-d7cc-4505-8bcb-401766214b5f sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:75 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:75 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:75 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:75 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:75 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:75 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:75 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:75 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 226: {consumer-MessageConsumer2-1-0beb35a0-5083-43ff-8b3f-c65afbec59f4=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@7f69d591}
15:05:75 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 226
15:05:75 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:75 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:75 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:75 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:76 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:80 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-0beb35a0-5083-43ff-8b3f-c65afbec59f4 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:87 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:87 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:87 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:87 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 228: {consumer-MessageConsumer2-1-c705a902-93d9-4341-936f-ad47d6bf6f6e=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@61078690}
15:05:88 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 228
15:05:88 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:88 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:88 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:88 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:88 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:92 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-c705a902-93d9-4341-936f-ad47d6bf6f6e sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:99 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:99 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:99 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:99 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 230: {consumer-MessageConsumer2-1-480495c0-9b35-4744-8530-c2adc8e32de1=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@1cb3ec38}
15:05:99 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 230
15:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:99 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:04 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-480495c0-9b35-4744-8530-c2adc8e32de1 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:11 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:11 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:11 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:11 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:11 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:11 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:11 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:11 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 232: {consumer-MessageConsumer2-1-02bd5472-c655-4462-b027-43e1b1d8f974=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@403132fc}
15:05:12 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 232
15:05:12 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:12 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:12 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:12 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:12 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:16 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-02bd5472-c655-4462-b027-43e1b1d8f974 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:23 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:23 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:23 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:23 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:23 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:23 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:23 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:23 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 234: {consumer-MessageConsumer2-1-4c4ad933-f55a-4d20-9d58-05175d9dd577=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@71c5b236}
15:05:23 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 234
15:05:23 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:23 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:23 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:23 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:23 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:28 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-4c4ad933-f55a-4d20-9d58-05175d9dd577 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:34 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:34 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:34 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:34 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:34 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:34 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:34 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:34 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 236: {consumer-MessageConsumer2-1-6628c272-77d8-4117-aedb-f6f1db8bda80=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@2cab9998}
15:05:34 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 236
15:05:34 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:34 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:34 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:34 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:34 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:38 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-6628c272-77d8-4117-aedb-f6f1db8bda80 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:46 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:46 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:46 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:46 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:46 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:46 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:46 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:46 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 238: {consumer-MessageConsumer2-1-83bcc005-f645-4323-843f-e74e90f6af11=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@2f7a7219}
15:05:46 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 238
15:05:46 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:46 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:46 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:46 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:46 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:51 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-83bcc005-f645-4323-843f-e74e90f6af11 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:58 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:58 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:58 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:58 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:58 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:58 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:58 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:59 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 240: {consumer-MessageConsumer2-1-e68b3391-2718-4417-a2ea-e883facdab39=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@669513d8}
15:05:59 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 240
15:05:59 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:59 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:59 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:59 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:59 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:63 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-e68b3391-2718-4417-a2ea-e883facdab39 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:70 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:70 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:70 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:70 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:70 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:70 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:70 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:70 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 242: {consumer-MessageConsumer2-1-c1ed8374-3b41-46e6-b779-0653cb0427e2=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@3a1d593e}
15:05:70 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 242
15:05:70 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:70 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:70 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:70 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:70 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:73 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-c1ed8374-3b41-46e6-b779-0653cb0427e2 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:81 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:81 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:81 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:81 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 244: {consumer-MessageConsumer2-1-335ed4ac-cea8-4085-a79b-f938ddcd9693=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@4a8a60bc}
15:05:82 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 244
15:05:82 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:82 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:82 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:82 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:82 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:83 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-335ed4ac-cea8-4085-a79b-f938ddcd9693 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:93 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:93 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:93 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:93 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 246: {consumer-MessageConsumer2-1-ce8ef8d5-05ce-4649-8b21-13852ab697ea=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@361c294e}
15:05:93 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 246
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:93 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:96 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-ce8ef8d5-05ce-4649-8b21-13852ab697ea sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:05 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:05 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:05 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:05 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:05 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:05 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:05 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:05 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 248: {consumer-MessageConsumer2-1-b798af47-ed91-44e3-acd3-71715af52f7b=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@7859e786}
15:05:05 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 248
15:05:05 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:05 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:05 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:05 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:05 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:09 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-b798af47-ed91-44e3-acd3-71715af52f7b sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:16 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:16 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:16 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:16 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:16 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:16 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:16 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:16 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 250: {consumer-MessageConsumer2-1-01dac536-6587-49c2-906b-dc2976ecfb5d=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@285d851a}
15:05:17 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 250
15:05:17 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:17 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:17 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:17 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:17 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:21 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-01dac536-6587-49c2-906b-dc2976ecfb5d sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:28 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:28 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:28 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:28 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 252: {consumer-MessageConsumer2-1-93085790-6087-4ba6-8c50-dca6b04c84c2=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@314b8f2d}
15:05:28 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 252
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:28 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:31 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-93085790-6087-4ba6-8c50-dca6b04c84c2 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:39 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:39 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:39 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:39 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:39 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:39 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:39 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:39 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 254: {consumer-MessageConsumer2-1-6bcef1c2-b380-4f16-a7e7-3743b88988fb=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@664a9613}
15:05:39 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 254
15:05:39 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:39 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:39 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:39 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:39 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:42 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-6bcef1c2-b380-4f16-a7e7-3743b88988fb sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:50 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:50 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:50 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:50 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:50 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:50 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:50 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:50 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 256: {consumer-MessageConsumer2-1-43a5b78a-c57a-4b06-b785-ec07b85824a0=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@5118388b}
15:05:50 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 256
15:05:51 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:51 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:51 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:51 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:51 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:53 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-43a5b78a-c57a-4b06-b785-ec07b85824a0 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:62 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:62 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:62 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:62 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:62 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:62 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:62 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:62 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 258: {consumer-MessageConsumer2-1-6aa649fd-7c6a-4243-ad43-63f3361deb0d=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@15a902e7}
15:05:62 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 258
15:05:62 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:62 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:62 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:62 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:62 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:67 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-6aa649fd-7c6a-4243-ad43-63f3361deb0d sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:74 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:74 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:74 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:74 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:74 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:74 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:74 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:74 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 260: {consumer-MessageConsumer2-1-ccde84d3-cc5a-45a4-a6e8-a6280920fc93=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@7876d598}
15:05:74 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 260
15:05:74 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:74 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:74 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:74 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:74 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:78 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-ccde84d3-cc5a-45a4-a6e8-a6280920fc93 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:86 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:86 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:86 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:86 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:86 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:86 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:86 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:86 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 262: {consumer-MessageConsumer2-1-1a3adcb9-3a5c-4d2c-b398-a5cb3503f8f6=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@4a3e3e8b}
15:05:86 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 262
15:05:86 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:86 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:86 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:86 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:86 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:89 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-1a3adcb9-3a5c-4d2c-b398-a5cb3503f8f6 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:98 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:98 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:98 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:98 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 264: {consumer-MessageConsumer2-1-42736aad-37fc-4902-ab09-f6f05167e83d=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@5af28b27}
15:05:98 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 264
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:98 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:01 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-42736aad-37fc-4902-ab09-f6f05167e83d sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:10 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:10 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:10 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:10 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 266: {consumer-MessageConsumer2-1-5d05f90c-304b-4492-b69d-4f6b48a28369=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@71104a4}
15:05:10 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 266
15:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:10 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:10 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:14 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-5d05f90c-304b-4492-b69d-4f6b48a28369 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:22 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:22 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:22 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:22 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:22 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:22 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:22 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:22 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 268: {consumer-MessageConsumer2-1-0089e9dd-b29b-4c5a-8100-815e9cc42b1c=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@4985cbcb}
15:05:22 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 268
15:05:22 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:22 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:23 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:23 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:23 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:24 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-0089e9dd-b29b-4c5a-8100-815e9cc42b1c sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:33 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:33 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:33 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:33 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:33 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:33 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:33 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:34 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 270: {consumer-MessageConsumer2-1-aa786ad4-d6c4-444b-b5ba-0ad13551a144=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@72f46e16}
15:05:34 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 270
15:05:34 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:34 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:34 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:34 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:34 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:36 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-aa786ad4-d6c4-444b-b5ba-0ad13551a144 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:45 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:45 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:45 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:45 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:45 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:45 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:45 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:45 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 272: {consumer-MessageConsumer2-1-e3b0c06f-1b4c-4267-99d3-1a34a3d86e1d=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@3c9168dc}
15:05:45 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 272
15:05:45 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:45 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:45 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:45 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:45 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:47 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-e3b0c06f-1b4c-4267-99d3-1a34a3d86e1d sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:57 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:57 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:57 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:57 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:57 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:57 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:57 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:57 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 274: {consumer-MessageConsumer2-1-c8291bdc-edf9-4f32-a7d2-282a1c90602a=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@332a7fce}
15:05:57 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 274
15:05:57 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:57 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:57 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:57 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:57 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:59 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-c8291bdc-edf9-4f32-a7d2-282a1c90602a sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:68 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:68 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:68 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:68 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:68 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:68 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:68 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:68 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 276: {consumer-MessageConsumer2-1-3fedac5c-c847-42c8-b701-a5898373eac7=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@549621f3}
15:05:68 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 276
15:05:68 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:68 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:69 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:69 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:69 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:72 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-3fedac5c-c847-42c8-b701-a5898373eac7 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:80 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:80 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:80 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:80 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:80 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:80 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:81 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 278: {consumer-MessageConsumer2-1-4c7eda0e-ab46-4bfb-970f-c7fcbaeb8006=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@54361a9}
15:05:81 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 278
15:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:81 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:85 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-4c7eda0e-ab46-4bfb-970f-c7fcbaeb8006 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:93 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:93 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:93 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:93 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 280: {consumer-MessageConsumer2-1-25e6565e-206f-4edf-a386-c3cba89718fb=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@32232e55}
15:05:93 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 280
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:93 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:96 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-25e6565e-206f-4edf-a386-c3cba89718fb sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:04 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:04 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:04 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:04 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:05 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 282: {consumer-MessageConsumer2-1-21828177-d94e-4e20-9fd1-6b2cfbc757b8=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@5217f3d0}
15:05:05 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 282
15:05:05 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:05 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:05 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:05 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:05 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:08 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-21828177-d94e-4e20-9fd1-6b2cfbc757b8 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:16 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:16 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:16 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:16 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:16 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:16 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:17 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:17 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 284: {consumer-MessageConsumer2-1-102800d2-8067-43cf-8fe9-709d8c8e8083=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@37ebc9d8}
15:05:17 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 284
15:05:17 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:17 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:17 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:17 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:17 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:19 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-102800d2-8067-43cf-8fe9-709d8c8e8083 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:28 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:28 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:28 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:28 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 286: {consumer-MessageConsumer2-1-89f27923-2096-40f1-ba6a-ebb4469e2822=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@293bb8a5}
15:05:28 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 286
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:28 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:29 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:29 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:29 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:30 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-89f27923-2096-40f1-ba6a-ebb4469e2822 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:39 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:39 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:39 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:39 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:39 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:39 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:40 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 288: {consumer-MessageConsumer2-1-d3bfd0a3-90f2-4254-a802-acaa0667d9ff=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@2416a51}
15:05:40 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 288
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:40 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:40 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:42 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-d3bfd0a3-90f2-4254-a802-acaa0667d9ff sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:51 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:51 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:51 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:51 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:51 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:51 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:51 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:51 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 290: {consumer-MessageConsumer2-1-14fe743e-74c7-4480-bde8-6af328118d46=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6fa590ba}
15:05:51 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 290
15:05:51 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:51 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:52 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:52 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:52 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:54 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-14fe743e-74c7-4480-bde8-6af328118d46 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:63 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:63 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:63 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:63 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:63 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:63 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:63 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:63 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 292: {consumer-MessageConsumer2-1-4be4c43b-260d-4b6f-8a83-6cab6e128b2f=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6e9319f}
15:05:64 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 292
15:05:64 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:64 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:64 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:64 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:64 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:65 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-4be4c43b-260d-4b6f-8a83-6cab6e128b2f sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:74 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:74 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=4, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=4, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:74 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:74 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:74 [main] INFO  listeners.MessageRebalanceListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:74 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:74 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:75 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 294: {consumer-MessageConsumer2-1-4e479391-6f07-48e1-9076-99ec02704cfa=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@72e34f77}
15:05:75 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 294
15:05:75 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:75 [main] INFO  listeners.MessageRebalanceListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:75 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:75 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:75 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:54 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 5000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

15:05:80 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
15:05:80 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
15:05:80 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684760384802
15:05:80 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Subscribed to topic(s): test-topic-replicated
15:05:11 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
15:05:11 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
15:05:12 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:13 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:13 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 296: {consumer-MessageConsumer2-1-b6153f1c-eaf1-482a-aa38-058db07a357e=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@7651218e}
15:05:13 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 296
15:05:14 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:14 [main] INFO  listeners.MessageRebalancedListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:15 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:15 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
15:05:15 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
16:05:22 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-b6153f1c-eaf1-482a-aa38-058db07a357e sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
16:05:22 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
16:05:22 [main] ERROR c.MessageConsumerRebalancedListener - Exception in pollKafka :org.apache.kafka.clients.consumer.CommitFailedException: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
16:05:22 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
16:05:22 [main] INFO  listeners.MessageRebalancedListener - onPartitionsRevoked : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
16:05:22 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
16:05:22 [main] ERROR o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] User provided listener listeners.MessageRebalancedListener failed on invocation of onPartitionsLost for partitions [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
org.apache.kafka.clients.consumer.CommitFailedException: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetCommitRequest(ConsumerCoordinator.java:1061)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:936)
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1387)
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1349)
	at listeners.MessageRebalancedListener.onPartitionsRevoked(MessageRebalancedListener.java:22)
	at org.apache.kafka.clients.consumer.ConsumerRebalanceListener.onPartitionsLost(ConsumerRebalanceListener.java:198)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsLost(ConsumerCoordinator.java:310)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onLeavePrepare(ConsumerCoordinator.java:709)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.close(AbstractCoordinator.java:887)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.close(ConsumerCoordinator.java:832)
	at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:2294)
	at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:2261)
	at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:2211)
	at consumer.MessageConsumerRebalancedListener.pollKafka(MessageConsumerRebalancedListener.java:53)
	at consumer.MessageConsumerRebalancedListener.main(MessageConsumerRebalancedListener.java:59)
16:05:22 [main] ERROR o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failed to close coordinator
org.apache.kafka.common.KafkaException: User rebalance callback throws an error
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onLeavePrepare(ConsumerCoordinator.java:715)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.close(AbstractCoordinator.java:887)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.close(ConsumerCoordinator.java:832)
	at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:2294)
	at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:2261)
	at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:2211)
	at consumer.MessageConsumerRebalancedListener.pollKafka(MessageConsumerRebalancedListener.java:53)
	at consumer.MessageConsumerRebalancedListener.main(MessageConsumerRebalancedListener.java:59)
Caused by: org.apache.kafka.clients.consumer.CommitFailedException: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetCommitRequest(ConsumerCoordinator.java:1061)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:936)
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1387)
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1349)
	at listeners.MessageRebalancedListener.onPartitionsRevoked(MessageRebalancedListener.java:22)
	at org.apache.kafka.clients.consumer.ConsumerRebalanceListener.onPartitionsLost(ConsumerRebalanceListener.java:198)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsLost(ConsumerCoordinator.java:310)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onLeavePrepare(ConsumerCoordinator.java:709)
	... 7 common frames omitted
16:05:33 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 5000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

16:05:59 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
16:05:59 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
16:05:59 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684760459594
16:05:60 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Subscribed to topic(s): test-topic-replicated
16:05:86 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
16:05:86 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
16:05:87 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
16:05:88 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
16:05:88 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 298: {consumer-MessageConsumer2-1-cb575553-2d43-4fa4-9051-6c0847bd51f6=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@7651218e}
16:05:88 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 298
16:05:89 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
16:05:89 [main] INFO  listeners.MessageRebalancedListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
16:05:90 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
16:05:90 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
16:05:90 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional[4], currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9093 (id: 1 rack: null), epoch=4}}
16:05:25 [main] INFO  producer.MessageProducer - Selected Option is : 1 
16:05:26 [main] INFO  producer.MessageProducer - Entered message is haha
16:05:30 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

16:05:53 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
16:05:53 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
16:05:53 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684760468529
16:05:82 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
16:05:85 [main] INFO  producer.MessageProducer - Message haha sent successfully for the key null
16:05:85 [main] INFO  producer.MessageProducer - Published message Offset is 8 and the partition is 0
16:05:85 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
16:05:86 [main] INFO  c.MessageConsumerRebalancedListener - Consumer Record key is null and the value is haha and the partition is 0
16:05:10 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 5000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

16:05:35 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
16:05:35 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
16:05:35 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684762310352
16:05:36 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Subscribed to topic(s): test-topic-replicated
16:05:62 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
16:05:62 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
16:05:62 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
16:05:63 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
16:05:64 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 300: {consumer-MessageConsumer2-1-5374f74b-9994-4b78-a18f-9ab02257e3f6=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@7651218e}
16:05:64 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 300
16:05:64 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
16:05:64 [main] INFO  listeners.MessageRebalancedListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
16:05:64 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Seeking to EARLIEST offset of partition test-topic-replicated-0
16:05:64 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Seeking to EARLIEST offset of partition test-topic-replicated-1
16:05:64 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Seeking to EARLIEST offset of partition test-topic-replicated-2
16:05:66 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition test-topic-replicated-0 to offset 0.
16:05:66 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition test-topic-replicated-1 to offset 0.
16:05:66 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition test-topic-replicated-2 to offset 0.
16:05:69 [main] INFO  c.MessageConsumerRebalancedListener - Consumer Record key is null and the value is Welcome my child and the partition is 0
16:05:69 [main] INFO  c.MessageConsumerRebalancedListener - Consumer Record key is null and the value is heyo and the partition is 0
16:05:69 [main] INFO  c.MessageConsumerRebalancedListener - Consumer Record key is null and the value is hehe and the partition is 0
16:05:69 [main] INFO  c.MessageConsumerRebalancedListener - Consumer Record key is null and the value is ghi and the partition is 0
16:05:69 [main] INFO  c.MessageConsumerRebalancedListener - Consumer Record key is null and the value is trrrt and the partition is 0
16:05:69 [main] INFO  c.MessageConsumerRebalancedListener - Consumer Record key is null and the value is testtttt and the partition is 0
16:05:69 [main] INFO  c.MessageConsumerRebalancedListener - Consumer Record key is null and the value is Heyo and the partition is 0
16:05:69 [main] INFO  c.MessageConsumerRebalancedListener - Consumer Record key is null and the value is heyo and the partition is 0
16:05:69 [main] INFO  c.MessageConsumerRebalancedListener - Consumer Record key is null and the value is haha and the partition is 0
16:05:69 [main] INFO  c.MessageConsumerRebalancedListener - Consumer Record key is null and the value is heyo and the partition is 1
16:05:69 [main] INFO  c.MessageConsumerRebalancedListener - Consumer Record key is null and the value is Welcome my friend and the partition is 1
16:05:69 [main] INFO  c.MessageConsumerRebalancedListener - Consumer Record key is A and the value is apple and the partition is 1
16:05:69 [main] INFO  c.MessageConsumerRebalancedListener - Consumer Record key is null and the value is a and the partition is 1
16:05:69 [main] INFO  c.MessageConsumerRebalancedListener - Consumer Record key is null and the value is b and the partition is 1
16:05:69 [main] INFO  c.MessageConsumerRebalancedListener - Consumer Record key is null and the value is c and the partition is 1
16:05:69 [main] INFO  c.MessageConsumerRebalancedListener - Consumer Record key is null and the value is haha and the partition is 1
16:05:69 [main] INFO  c.MessageConsumerRebalancedListener - Consumer Record key is null and the value is haha and the partition is 1
16:05:69 [main] INFO  c.MessageConsumerRebalancedListener - Consumer Record key is null and the value is hahaha and the partition is 1
16:05:69 [main] INFO  c.MessageConsumerRebalancedListener - Consumer Record key is null and the value is bebe and the partition is 2
16:05:69 [main] INFO  c.MessageConsumerRebalancedListener - Consumer Record key is null and the value is tehkts and the partition is 2
16:05:69 [main] INFO  c.MessageConsumerRebalancedListener - Consumer Record key is null and the value is next and the partition is 2
16:05:69 [main] INFO  c.MessageConsumerRebalancedListener - Consumer Record key is null and the value is prrrt and the partition is 2
16:05:69 [main] INFO  c.MessageConsumerRebalancedListener - Consumer Record key is null and the value is abc and the partition is 2
16:05:69 [main] INFO  c.MessageConsumerRebalancedListener - Consumer Record key is null and the value is hahahahaha and the partition is 2
16:05:32 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 5000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

16:05:57 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
16:05:57 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
16:05:57 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684762353573
16:05:58 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Subscribed to topic(s): test-topic-replicated
16:05:84 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
16:05:84 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
16:05:85 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
16:05:85 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
16:05:86 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 302: {consumer-MessageConsumer2-1-3a993dc3-6ff6-42ff-b766-a8c461606847=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@7651218e}
16:05:86 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 302
16:05:86 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
16:05:86 [main] INFO  listeners.MessageRebalancedListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
16:05:86 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Seeking to LATEST offset of partition test-topic-replicated-0
16:05:86 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Seeking to LATEST offset of partition test-topic-replicated-1
16:05:86 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Seeking to LATEST offset of partition test-topic-replicated-2
16:05:88 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition test-topic-replicated-0 to offset 9.
16:05:88 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition test-topic-replicated-1 to offset 9.
16:05:88 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition test-topic-replicated-2 to offset 6.
15:05:12 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 5000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

15:05:39 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
15:05:39 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
15:05:39 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684844516393
15:05:40 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Subscribed to topic(s): test-topic-replicated
15:05:74 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
15:05:74 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
15:05:74 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:76 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:77 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 304: {consumer-MessageConsumer2-1-67388318-bbab-46d5-847f-3f719b542e05=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@7651218e}
15:05:78 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 304
15:05:78 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:78 [main] INFO  listeners.MessageRebalancedListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:79 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Seeking to LATEST offset of partition test-topic-replicated-0
15:05:79 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Seeking to LATEST offset of partition test-topic-replicated-1
15:05:79 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Seeking to LATEST offset of partition test-topic-replicated-2
15:05:83 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition test-topic-replicated-0 to offset 9.
15:05:84 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition test-topic-replicated-1 to offset 9.
15:05:84 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition test-topic-replicated-2 to offset 6.
15:05:47 [main] INFO  producer.MessageProducer - Selected Option is : 1 
15:05:25 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 5000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

15:05:51 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
15:05:51 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
15:05:51 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684844544509
15:05:51 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Subscribed to topic(s): test-topic-replicated
15:05:48 [main] INFO  producer.MessageProducer - Entered message is HAHAAHA
15:05:51 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

15:05:74 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
15:05:74 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
15:05:74 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684844545744
15:05:03 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
15:05:08 [main] INFO  producer.MessageProducer - Message HAHAAHA sent successfully for the key null
15:05:08 [main] INFO  producer.MessageProducer - Published message Offset is 9 and the partition is 0
15:05:08 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
15:05:80 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
15:05:80 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
15:05:80 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:81 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:82 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 306: {consumer-MessageConsumer2-1-0a3e4343-042d-4a75-b40a-14673c57b752=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6d366c9b}
15:05:82 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 306
15:05:82 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:84 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9092 (id: 0 rack: null), epoch=6}}
15:05:84 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9092 (id: 0 rack: null), epoch=6}}
15:05:84 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9092 (id: 0 rack: null), epoch=6}}
15:05:86 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-0a3e4343-042d-4a75-b40a-14673c57b752 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:89 [main] INFO  consumer.MessageConsumer - Consumer Record key is null and the value is HAHAAHA and the partition is 0
15:05:89 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:89 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=10, leaderEpoch=6, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=null, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=null, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:89 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:89 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:89 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:90 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:91 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 308: {consumer-MessageConsumer2-1-8017a09a-fd47-476d-a3cf-a2a6998534d3=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@3c9168dc}
15:05:91 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 308
15:05:91 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:91 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9092 (id: 0 rack: null), epoch=6}}
15:05:91 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9092 (id: 0 rack: null), epoch=6}}
15:05:91 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9092 (id: 0 rack: null), epoch=6}}
15:05:93 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-8017a09a-fd47-476d-a3cf-a2a6998534d3 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:93 [main] INFO  consumer.MessageConsumer - Consumer Record key is null and the value is HAHAAHA and the partition is 0
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:93 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=10, leaderEpoch=6, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=null, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=null, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:93 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:94 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:94 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 310: {consumer-MessageConsumer2-1-67422ee5-0336-471d-bb58-efe9332e3acf=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@332a7fce}
15:05:94 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 310
15:05:95 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:95 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9092 (id: 0 rack: null), epoch=6}}
15:05:95 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9092 (id: 0 rack: null), epoch=6}}
15:05:95 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9092 (id: 0 rack: null), epoch=6}}
15:05:97 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-67422ee5-0336-471d-bb58-efe9332e3acf sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:96 [main] INFO  consumer.MessageConsumer - Consumer Record key is null and the value is HAHAAHA and the partition is 0
15:05:96 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:96 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=10, leaderEpoch=6, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=null, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=null, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:96 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:96 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:96 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:97 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:97 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 312: {consumer-MessageConsumer2-1-0dc84be0-b0f8-44ed-b16e-6c371c411a60=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@549621f3}
15:05:97 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 312
15:05:97 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9092 (id: 0 rack: null), epoch=6}}
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9092 (id: 0 rack: null), epoch=6}}
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9092 (id: 0 rack: null), epoch=6}}
15:05:00 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-0dc84be0-b0f8-44ed-b16e-6c371c411a60 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:98 [main] INFO  consumer.MessageConsumer - Consumer Record key is null and the value is HAHAAHA and the partition is 0
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
15:05:98 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {test-topic-replicated-0=OffsetAndMetadata{offset=10, leaderEpoch=6, metadata=''}, test-topic-replicated-1=OffsetAndMetadata{offset=9, leaderEpoch=null, metadata=''}, test-topic-replicated-2=OffsetAndMetadata{offset=6, leaderEpoch=null, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
15:05:98 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:98 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:99 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
15:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 314: {consumer-MessageConsumer2-1-71c638e0-4dfb-4984-a569-0b2c3443172b=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@54361a9}
15:05:99 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 314
15:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-2 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9092 (id: 0 rack: null), epoch=6}}
15:05:00 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-0 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9092 (id: 0 rack: null), epoch=6}}
15:05:00 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Setting offset for partition test-topic-replicated-1 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=DESKTOP-OVCB8LL:9092 (id: 0 rack: null), epoch=6}}
15:05:01 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-71c638e0-4dfb-4984-a569-0b2c3443172b sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
15:05:74 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = messageconsumer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

15:05:00 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
15:05:00 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
15:05:00 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684845704000
15:05:00 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Subscribed to topic(s): test-topic-replicated
15:05:27 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
15:05:27 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
15:05:27 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] (Re-)joining group
15:05:28 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] (Re-)joining group
15:05:28 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Finished assignment for group at generation 1: {consumer-messageconsumer-1-3ef970c5-7ba7-4871-b5ae-65da7bd22738=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@741b3bc3}
15:05:29 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Successfully joined group with generation 1
15:05:29 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:29 [main] INFO  listeners.MessageRebalancedListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:29 [main] ERROR listeners.MessageRebalancedListener - Exception Occurred while reading the file : java.io.FileNotFoundException: consumers\src\main\resources\offset.ser (The system cannot find the file specified)
15:05:29 [main] INFO  listeners.MessageRebalancedListener - Offsetmap: {}
15:05:30 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Found no committed offset for partition test-topic-replicated-0
15:05:30 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Found no committed offset for partition test-topic-replicated-1
15:05:30 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Found no committed offset for partition test-topic-replicated-2
15:05:32 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Resetting offset for partition test-topic-replicated-1 to offset 9.
15:05:32 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Resetting offset for partition test-topic-replicated-2 to offset 6.
15:05:32 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Resetting offset for partition test-topic-replicated-0 to offset 10.
15:05:97 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = messageconsumer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

15:05:23 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
15:05:23 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
15:05:23 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684845726230
15:05:23 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Subscribed to topic(s): test-topic-replicated
15:05:50 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
15:05:51 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
15:05:51 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] (Re-)joining group
15:05:52 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] (Re-)joining group
15:05:52 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Finished assignment for group at generation 3: {consumer-messageconsumer-1-62500d28-263c-4efd-a187-d609f07d1eea=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@741b3bc3}
15:05:53 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Successfully joined group with generation 3
15:05:53 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:53 [main] INFO  listeners.MessageRebalancedListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:53 [main] ERROR listeners.MessageRebalancedListener - Exception Occurred while reading the file : java.io.FileNotFoundException: consumers\src\main\resources\offset.ser (The system cannot find the file specified)
15:05:53 [main] INFO  listeners.MessageRebalancedListener - Offsetmap: {}
15:05:54 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Found no committed offset for partition test-topic-replicated-0
15:05:54 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Found no committed offset for partition test-topic-replicated-1
15:05:54 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Found no committed offset for partition test-topic-replicated-2
15:05:55 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Resetting offset for partition test-topic-replicated-0 to offset 10.
15:05:56 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Resetting offset for partition test-topic-replicated-1 to offset 9.
15:05:56 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Resetting offset for partition test-topic-replicated-2 to offset 6.
15:05:35 [main] INFO  producer.MessageProducer - Selected Option is : 1 
15:05:38 [main] INFO  producer.MessageProducer - Entered message is test
15:05:42 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

15:05:64 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
15:05:64 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
15:05:64 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684845792645
15:05:92 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
15:05:98 [main] INFO  producer.MessageProducer - Message test sent successfully for the key null
15:05:98 [main] INFO  producer.MessageProducer - Published message Offset is 10 and the partition is 0
15:05:98 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
15:05:40 [main] INFO  producer.MessageProducer - Entered message is ahah
15:05:40 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

15:05:40 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
15:05:40 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
15:05:40 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684845794406
15:05:41 [kafka-producer-network-thread | producer-2] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
15:05:42 [main] INFO  producer.MessageProducer - Message ahah sent successfully for the key null
15:05:42 [main] INFO  producer.MessageProducer - Published message Offset is 9 and the partition is 1
15:05:42 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
15:05:44 [main] INFO  producer.MessageProducer - Entered message is prrrt
15:05:44 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

15:05:45 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
15:05:45 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
15:05:45 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684845798456
15:05:50 [kafka-producer-network-thread | producer-3] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
15:05:50 [kafka-producer-network-thread | producer-3] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-3] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
15:05:51 [main] INFO  producer.MessageProducer - Message prrrt sent successfully for the key null
15:05:52 [main] INFO  producer.MessageProducer - Published message Offset is 6 and the partition is 2
15:05:52 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
15:05:99 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = messageconsumer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

15:05:25 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
15:05:25 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
15:05:25 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684845811248
15:05:25 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Subscribed to topic(s): test-topic-replicated
15:05:51 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
15:05:51 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
15:05:51 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] (Re-)joining group
15:05:52 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] (Re-)joining group
15:05:53 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Finished assignment for group at generation 5: {consumer-messageconsumer-1-191dbe87-7481-43a8-a8ec-74ee29cf7871=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@741b3bc3}
15:05:53 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Successfully joined group with generation 5
15:05:53 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:53 [main] INFO  listeners.MessageRebalancedListener - onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2]
15:05:53 [main] ERROR listeners.MessageRebalancedListener - Exception Occurred while reading the file : java.io.FileNotFoundException: consumers\src\main\resources\offset.ser (The system cannot find the file specified)
15:05:53 [main] INFO  listeners.MessageRebalancedListener - Offsetmap: {}
15:05:54 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Found no committed offset for partition test-topic-replicated-0
15:05:54 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Found no committed offset for partition test-topic-replicated-1
15:05:54 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Found no committed offset for partition test-topic-replicated-2
15:05:56 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Resetting offset for partition test-topic-replicated-0 to offset 11.
15:05:56 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Resetting offset for partition test-topic-replicated-1 to offset 10.
15:05:56 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Resetting offset for partition test-topic-replicated-2 to offset 7.
15:05:40 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = messageconsumer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

15:05:65 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
15:05:65 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
15:05:65 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684846129651
15:05:65 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Subscribed to topic(s): test-topic-replicated
15:05:92 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
15:05:92 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
15:05:93 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] (Re-)joining group
15:05:94 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] (Re-)joining group
15:05:94 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Finished assignment for group at generation 7: {consumer-messageconsumer-1-916cf0ca-66ae-412f-aa7f-7d91d4d18709=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@741b3bc3}
15:05:94 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Successfully joined group with generation 7
15:05:95 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:95 [main] ERROR listeners.MessageRebalancedListener - Exception Occurred while reading the file : java.io.FileNotFoundException: consumers\src\main\resources\offset.ser (The system cannot find the file specified)
15:05:95 [main] INFO  listeners.MessageRebalancedListener - Inside onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2] 
15:05:96 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Found no committed offset for partition test-topic-replicated-0
15:05:96 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Found no committed offset for partition test-topic-replicated-1
15:05:96 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Found no committed offset for partition test-topic-replicated-2
15:05:97 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Resetting offset for partition test-topic-replicated-0 to offset 11.
15:05:98 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Resetting offset for partition test-topic-replicated-1 to offset 10.
15:05:98 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Resetting offset for partition test-topic-replicated-2 to offset 7.
15:05:63 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = messageconsumer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

15:05:89 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
15:05:89 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
15:05:89 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684846198892
15:05:89 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Subscribed to topic(s): test-topic-replicated
15:05:06 [main] WARN  o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
15:05:19 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
15:05:19 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
15:05:19 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] (Re-)joining group
15:05:20 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] (Re-)joining group
15:05:21 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Finished assignment for group at generation 9: {consumer-messageconsumer-1-747add80-199c-4f6f-be70-fa5fdede1d61=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@21005f6c}
15:05:21 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Successfully joined group with generation 9
15:05:21 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Adding newly assigned partitions: test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2
15:05:22 [main] ERROR listeners.MessageRebalancedListener - Exception Occurred while reading the file : java.io.EOFException
15:05:22 [main] INFO  listeners.MessageRebalancedListener - Inside onPartitionsAssigned : [test-topic-replicated-0, test-topic-replicated-1, test-topic-replicated-2] 
15:05:23 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Found no committed offset for partition test-topic-replicated-0
15:05:23 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Found no committed offset for partition test-topic-replicated-1
15:05:23 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Found no committed offset for partition test-topic-replicated-2
15:05:24 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Resetting offset for partition test-topic-replicated-1 to offset 10.
15:05:24 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Resetting offset for partition test-topic-replicated-2 to offset 7.
15:05:25 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-messageconsumer-1, groupId=messageconsumer] Resetting offset for partition test-topic-replicated-0 to offset 11.
16:05:61 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = itemsGroupid
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class deserializer.ItemDeserializer

16:05:86 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
16:05:86 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
16:05:86 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684849364864
16:05:87 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-itemsGroupid-1, groupId=itemsGroupid] Subscribed to topic(s): items
16:05:03 [main] WARN  o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-itemsGroupid-1, groupId=itemsGroupid] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
16:05:16 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-itemsGroupid-1, groupId=itemsGroupid] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
16:05:16 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-itemsGroupid-1, groupId=itemsGroupid] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
16:05:16 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-itemsGroupid-1, groupId=itemsGroupid] (Re-)joining group
16:05:17 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-itemsGroupid-1, groupId=itemsGroupid] (Re-)joining group
16:05:18 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-itemsGroupid-1, groupId=itemsGroupid] Finished assignment for group at generation 1: {consumer-itemsGroupid-1-a190c458-7a2f-41a5-9c95-d8037d42ccf4=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@42b64ab8}
16:05:18 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-itemsGroupid-1, groupId=itemsGroupid] Successfully joined group with generation 1
16:05:18 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-itemsGroupid-1, groupId=itemsGroupid] Adding newly assigned partitions: items-2, items-0, items-1
16:05:19 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-itemsGroupid-1, groupId=itemsGroupid] Found no committed offset for partition items-2
16:05:19 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-itemsGroupid-1, groupId=itemsGroupid] Found no committed offset for partition items-0
16:05:19 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-itemsGroupid-1, groupId=itemsGroupid] Found no committed offset for partition items-1
16:05:21 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-itemsGroupid-1, groupId=itemsGroupid] Resetting offset for partition items-2 to offset 0.
16:05:21 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-itemsGroupid-1, groupId=itemsGroupid] Resetting offset for partition items-0 to offset 0.
16:05:21 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-itemsGroupid-1, groupId=itemsGroupid] Resetting offset for partition items-1 to offset 0.
16:05:62 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class serializer.ItemSerializer

16:05:04 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
16:05:04 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
16:05:04 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684849592041
16:05:30 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
16:05:30 [main] INFO  serializer.ItemSerializer - Inside Serialization logic
16:05:39 [main] INFO  producer.ItemProducer - Message Item{id=1, itemName='LG TV', price=400.0} sent successfully for the key 1
16:05:40 [main] INFO  producer.ItemProducer - Published message Offset is 0 and the partition is 0
16:05:40 [main] INFO  serializer.ItemSerializer - Inside Serialization logic
16:05:41 [main] INFO  producer.ItemProducer - Message Item{id=2, itemName='Iphone', price=949.49} sent successfully for the key 2
16:05:41 [main] INFO  producer.ItemProducer - Published message Offset is 0 and the partition is 2
16:05:42 [main] INFO  deserializer.ItemDeserializer - Inside deserialize
16:05:65 [main] INFO  deserializer.ItemDeserializer - Inside deserialize
16:05:65 [main] INFO  consumer.ItemConsumer - Consumer Record key is 2 and the value is Item{id=2, itemName='Iphone', price=949.49} and the partition is 2
16:05:66 [main] INFO  consumer.ItemConsumer - Consumer Record key is 1 and the value is Item{id=1, itemName='LG TV', price=400.0} and the partition is 0
17:05:10 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 5000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

17:05:36 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
17:05:36 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
17:05:36 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684850586358
17:05:36 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Subscribed to topic(s): items
17:05:65 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
17:05:65 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
17:05:65 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
17:05:66 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
17:05:67 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 316: {consumer-MessageConsumer2-1-54cec6dd-fd85-46a8-94f8-5035d4f2a588=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6f0628de}
17:05:67 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 316
17:05:68 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: items-2, items-0, items-1
17:05:68 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-2
17:05:68 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-0
17:05:68 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-1
17:05:70 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-2 to offset 0.
17:05:70 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-0 to offset 0.
17:05:70 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-1 to offset 0.
17:05:80 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-54cec6dd-fd85-46a8-94f8-5035d4f2a588 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
17:05:74 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 2 and the value is {"id":2,"itemName":"Iphone","price":949.49} and the partition is 2
17:05:80 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=2, itemName='Iphone', price=949.49}
17:05:81 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 1 and the value is {"id":1,"itemName":"LG TV","price":400.0} and the partition is 0
17:05:81 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=1, itemName='LG TV', price=400.0}
17:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
17:05:81 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {items-2=OffsetAndMetadata{offset=1, leaderEpoch=6, metadata=''}, items-0=OffsetAndMetadata{offset=1, leaderEpoch=6, metadata=''}, items-1=OffsetAndMetadata{offset=0, leaderEpoch=null, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
17:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
17:05:81 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions items-2, items-0, items-1
17:05:81 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
17:05:82 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
17:05:82 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 318: {consumer-MessageConsumer2-1-319759a1-1c0d-482f-92e8-6fde0f1d79a0=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@63998bf4}
17:05:82 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 318
17:05:82 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: items-2, items-0, items-1
17:05:82 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-2
17:05:82 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-0
17:05:82 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-1
17:05:82 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-2 to offset 0.
17:05:82 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-0 to offset 0.
17:05:82 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-1 to offset 0.
17:05:83 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-319759a1-1c0d-482f-92e8-6fde0f1d79a0 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
17:05:83 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 2 and the value is {"id":2,"itemName":"Iphone","price":949.49} and the partition is 2
17:05:83 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=2, itemName='Iphone', price=949.49}
17:05:83 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 1 and the value is {"id":1,"itemName":"LG TV","price":400.0} and the partition is 0
17:05:83 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=1, itemName='LG TV', price=400.0}
17:05:83 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
17:05:83 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {items-2=OffsetAndMetadata{offset=1, leaderEpoch=6, metadata=''}, items-0=OffsetAndMetadata{offset=1, leaderEpoch=6, metadata=''}, items-1=OffsetAndMetadata{offset=0, leaderEpoch=null, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
17:05:83 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
17:05:83 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions items-2, items-0, items-1
17:05:83 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
17:05:83 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
17:05:84 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 320: {consumer-MessageConsumer2-1-85fac555-d957-4fa0-be0c-33a8dd249aef=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@7e0b9178}
17:05:84 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 320
17:05:84 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: items-2, items-0, items-1
17:05:84 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-2
17:05:84 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-0
17:05:84 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-1
17:05:84 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-1 to offset 0.
17:05:84 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-2 to offset 0.
17:05:84 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-0 to offset 0.
17:05:87 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-85fac555-d957-4fa0-be0c-33a8dd249aef sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
17:05:86 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 2 and the value is {"id":2,"itemName":"Iphone","price":949.49} and the partition is 2
17:05:86 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=2, itemName='Iphone', price=949.49}
17:05:86 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 1 and the value is {"id":1,"itemName":"LG TV","price":400.0} and the partition is 0
17:05:86 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=1, itemName='LG TV', price=400.0}
17:05:86 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
17:05:86 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {items-2=OffsetAndMetadata{offset=1, leaderEpoch=6, metadata=''}, items-0=OffsetAndMetadata{offset=1, leaderEpoch=6, metadata=''}, items-1=OffsetAndMetadata{offset=0, leaderEpoch=null, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
17:05:86 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
17:05:86 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions items-2, items-0, items-1
17:05:86 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
17:05:87 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
17:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 322: {consumer-MessageConsumer2-1-9e17aec9-4e8d-44b3-9a12-caa7b85be67d=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@61942c1}
17:05:87 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 322
17:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: items-2, items-0, items-1
17:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-2
17:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-0
17:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-1
17:05:87 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-2 to offset 0.
17:05:88 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-0 to offset 0.
17:05:88 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-1 to offset 0.
17:05:89 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-9e17aec9-4e8d-44b3-9a12-caa7b85be67d sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
17:05:89 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 2 and the value is {"id":2,"itemName":"Iphone","price":949.49} and the partition is 2
17:05:89 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=2, itemName='Iphone', price=949.49}
17:05:89 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 1 and the value is {"id":1,"itemName":"LG TV","price":400.0} and the partition is 0
17:05:89 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=1, itemName='LG TV', price=400.0}
17:05:89 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
17:05:89 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {items-2=OffsetAndMetadata{offset=1, leaderEpoch=6, metadata=''}, items-0=OffsetAndMetadata{offset=1, leaderEpoch=6, metadata=''}, items-1=OffsetAndMetadata{offset=0, leaderEpoch=null, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
17:05:89 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
17:05:89 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions items-2, items-0, items-1
17:05:89 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
17:05:89 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
17:05:89 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 324: {consumer-MessageConsumer2-1-85e88236-c13a-4ecb-b62f-3199ac83f6bf=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6f63c44f}
17:05:90 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 324
17:05:90 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: items-2, items-0, items-1
17:05:90 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-2
17:05:90 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-0
17:05:90 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-1
17:05:90 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-2 to offset 0.
17:05:90 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-0 to offset 0.
17:05:90 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-1 to offset 0.
17:05:93 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-85e88236-c13a-4ecb-b62f-3199ac83f6bf sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
17:05:91 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 2 and the value is {"id":2,"itemName":"Iphone","price":949.49} and the partition is 2
17:05:91 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=2, itemName='Iphone', price=949.49}
17:05:91 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 1 and the value is {"id":1,"itemName":"LG TV","price":400.0} and the partition is 0
17:05:91 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=1, itemName='LG TV', price=400.0}
17:05:91 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
17:05:91 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {items-2=OffsetAndMetadata{offset=1, leaderEpoch=6, metadata=''}, items-0=OffsetAndMetadata{offset=1, leaderEpoch=6, metadata=''}, items-1=OffsetAndMetadata{offset=0, leaderEpoch=null, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
17:05:91 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
17:05:91 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions items-2, items-0, items-1
17:05:91 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
17:05:91 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
17:05:92 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 326: {consumer-MessageConsumer2-1-877b07c5-8a8c-469d-9b95-fa51ecf751b7=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@408a247c}
17:05:92 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 326
17:05:92 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: items-2, items-0, items-1
17:05:92 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-2
17:05:92 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-0
17:05:92 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-1
17:05:92 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-2 to offset 0.
17:05:92 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-0 to offset 0.
17:05:92 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-1 to offset 0.
17:05:95 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-877b07c5-8a8c-469d-9b95-fa51ecf751b7 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
17:05:93 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 2 and the value is {"id":2,"itemName":"Iphone","price":949.49} and the partition is 2
17:05:93 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=2, itemName='Iphone', price=949.49}
17:05:93 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 1 and the value is {"id":1,"itemName":"LG TV","price":400.0} and the partition is 0
17:05:93 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=1, itemName='LG TV', price=400.0}
17:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
17:05:93 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {items-2=OffsetAndMetadata{offset=1, leaderEpoch=6, metadata=''}, items-0=OffsetAndMetadata{offset=1, leaderEpoch=6, metadata=''}, items-1=OffsetAndMetadata{offset=0, leaderEpoch=null, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
17:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
17:05:93 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions items-2, items-0, items-1
17:05:93 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
17:05:93 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
17:05:94 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 328: {consumer-MessageConsumer2-1-a9b3caa3-9342-4102-8be1-9825a9450658=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@62a8fd44}
17:05:94 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 328
17:05:94 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: items-2, items-0, items-1
17:05:94 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-2
17:05:94 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-0
17:05:94 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-1
17:05:94 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-2 to offset 0.
17:05:94 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-0 to offset 0.
17:05:94 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-1 to offset 0.
17:05:03 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-a9b3caa3-9342-4102-8be1-9825a9450658 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
17:05:96 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 2 and the value is {"id":2,"itemName":"Iphone","price":949.49} and the partition is 2
17:05:96 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=2, itemName='Iphone', price=949.49}
17:05:96 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 1 and the value is {"id":1,"itemName":"LG TV","price":400.0} and the partition is 0
17:05:96 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=1, itemName='LG TV', price=400.0}
17:05:96 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
17:05:96 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {items-2=OffsetAndMetadata{offset=1, leaderEpoch=6, metadata=''}, items-0=OffsetAndMetadata{offset=1, leaderEpoch=6, metadata=''}, items-1=OffsetAndMetadata{offset=0, leaderEpoch=null, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
17:05:96 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
17:05:96 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions items-2, items-0, items-1
17:05:96 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
17:05:96 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
17:05:96 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 330: {consumer-MessageConsumer2-1-8221c7f5-895b-4d7a-96ed-29aaa5839a4e=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@2e6ba49a}
17:05:97 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 330
17:05:97 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: items-2, items-0, items-1
17:05:97 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-2
17:05:97 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-0
17:05:97 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-1
17:05:97 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-2 to offset 0.
17:05:97 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-0 to offset 0.
17:05:97 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-1 to offset 0.
17:05:40 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

17:05:63 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
17:05:63 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
17:05:63 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684850645631
17:05:95 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
17:05:98 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-8221c7f5-895b-4d7a-96ed-29aaa5839a4e sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
17:05:98 [main] INFO  producer.ItemProducerApproach2 - Message {"id":1,"itemName":"LG TV","price":400.0} sent successfully for the key 1
17:05:98 [main] INFO  producer.ItemProducerApproach2 - Published message Offset is 1 and the partition is 0
17:05:99 [main] INFO  producer.ItemProducerApproach2 - Message {"id":2,"itemName":"Iphone","price":949.49} sent successfully for the key 2
17:05:99 [main] INFO  producer.ItemProducerApproach2 - Published message Offset is 1 and the partition is 2
17:05:98 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 2 and the value is {"id":2,"itemName":"Iphone","price":949.49} and the partition is 2
17:05:98 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=2, itemName='Iphone', price=949.49}
17:05:98 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 1 and the value is {"id":1,"itemName":"LG TV","price":400.0} and the partition is 0
17:05:99 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=1, itemName='LG TV', price=400.0}
17:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
17:05:99 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {items-2=OffsetAndMetadata{offset=1, leaderEpoch=6, metadata=''}, items-0=OffsetAndMetadata{offset=1, leaderEpoch=6, metadata=''}, items-1=OffsetAndMetadata{offset=0, leaderEpoch=null, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
17:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
17:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions items-2, items-0, items-1
17:05:99 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
17:05:99 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
17:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 332: {consumer-MessageConsumer2-1-4aff4abc-2134-4ead-86e9-88cf81c48252=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@5f212d84}
17:05:99 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 332
17:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: items-2, items-0, items-1
17:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-2
17:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-0
17:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-1
17:05:99 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-2 to offset 0.
17:05:99 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-0 to offset 0.
17:05:00 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-1 to offset 0.
17:05:10 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-4aff4abc-2134-4ead-86e9-88cf81c48252 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
17:05:00 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 2 and the value is {"id":2,"itemName":"Iphone","price":949.49} and the partition is 2
17:05:00 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=2, itemName='Iphone', price=949.49}
17:05:00 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 2 and the value is {"id":2,"itemName":"Iphone","price":949.49} and the partition is 2
17:05:00 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=2, itemName='Iphone', price=949.49}
17:05:00 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 1 and the value is {"id":1,"itemName":"LG TV","price":400.0} and the partition is 0
17:05:00 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=1, itemName='LG TV', price=400.0}
17:05:00 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 1 and the value is {"id":1,"itemName":"LG TV","price":400.0} and the partition is 0
17:05:00 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=1, itemName='LG TV', price=400.0}
17:05:00 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
17:05:00 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {items-2=OffsetAndMetadata{offset=2, leaderEpoch=6, metadata=''}, items-0=OffsetAndMetadata{offset=2, leaderEpoch=6, metadata=''}, items-1=OffsetAndMetadata{offset=0, leaderEpoch=null, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
17:05:00 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
17:05:00 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions items-2, items-0, items-1
17:05:00 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
17:05:01 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
17:05:01 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 334: {consumer-MessageConsumer2-1-e3ccb25c-494e-4302-b8af-c7b5ff3ce7e1=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@127d7908}
17:05:01 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 334
17:05:01 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: items-2, items-0, items-1
17:05:01 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-2
17:05:01 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-0
17:05:01 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-1
17:05:02 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-2 to offset 0.
17:05:02 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-0 to offset 0.
17:05:02 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-1 to offset 0.
17:05:12 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-e3ccb25c-494e-4302-b8af-c7b5ff3ce7e1 sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
17:05:03 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 2 and the value is {"id":2,"itemName":"Iphone","price":949.49} and the partition is 2
17:05:03 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=2, itemName='Iphone', price=949.49}
17:05:03 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 2 and the value is {"id":2,"itemName":"Iphone","price":949.49} and the partition is 2
17:05:03 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=2, itemName='Iphone', price=949.49}
17:05:03 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 1 and the value is {"id":1,"itemName":"LG TV","price":400.0} and the partition is 0
17:05:03 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=1, itemName='LG TV', price=400.0}
17:05:03 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 1 and the value is {"id":1,"itemName":"LG TV","price":400.0} and the partition is 0
17:05:03 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=1, itemName='LG TV', price=400.0}
17:05:03 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
17:05:03 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {items-2=OffsetAndMetadata{offset=2, leaderEpoch=6, metadata=''}, items-0=OffsetAndMetadata{offset=2, leaderEpoch=6, metadata=''}, items-1=OffsetAndMetadata{offset=0, leaderEpoch=null, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
17:05:03 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
17:05:03 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions items-2, items-0, items-1
17:05:03 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
17:05:03 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
17:05:03 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 336: {consumer-MessageConsumer2-1-2f19deb9-f277-48a9-a82e-a921ac677d00=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6b9c69a9}
17:05:04 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 336
17:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: items-2, items-0, items-1
17:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-2
17:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-0
17:05:04 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-1
17:05:04 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-2 to offset 0.
17:05:04 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-0 to offset 0.
17:05:04 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-1 to offset 0.
17:05:92 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

17:05:16 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
17:05:16 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
17:05:16 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684850681157
17:05:46 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
17:05:49 [main] INFO  producer.ItemProducerApproach2 - Message {"id":1,"itemName":"LG TV","price":400.0} sent successfully for the key 1
17:05:49 [main] INFO  producer.ItemProducerApproach2 - Published message Offset is 2 and the partition is 0
17:05:50 [main] INFO  producer.ItemProducerApproach2 - Message {"id":2,"itemName":"Iphone","price":949.49} sent successfully for the key 2
17:05:50 [main] INFO  producer.ItemProducerApproach2 - Published message Offset is 2 and the partition is 2
17:05:30 [main] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = MessageConsumer2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 5000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

17:05:55 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
17:05:56 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
17:05:56 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1684850702556
17:05:56 [main] INFO  o.a.k.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Subscribed to topic(s): items
17:05:83 [main] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Cluster ID: Pz1PUPG8SJ-i_kRzN_cXRw
17:05:83 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Discovered group coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null)
17:05:84 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
17:05:85 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
17:05:85 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 338: {consumer-MessageConsumer2-1-5099fd07-b3bf-4c78-a9c3-fbf1100cd35b=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@6f0628de}
17:05:85 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 338
17:05:86 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: items-2, items-0, items-1
17:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-2
17:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-0
17:05:87 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-1
17:05:88 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-2 to offset 0.
17:05:88 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-0 to offset 0.
17:05:89 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-1 to offset 0.
17:05:98 [kafka-coordinator-heartbeat-thread | MessageConsumer2] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Member consumer-MessageConsumer2-1-5099fd07-b3bf-4c78-a9c3-fbf1100cd35b sending LeaveGroup request to coordinator DESKTOP-OVCB8LL:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
17:05:92 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 2 and the value is {"id":2,"itemName":"Iphone","price":949.49} and the partition is 2
17:05:98 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=2, itemName='Iphone', price=949.49}
17:05:99 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 2 and the value is {"id":2,"itemName":"Iphone","price":949.49} and the partition is 2
17:05:99 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=2, itemName='Iphone', price=949.49}
17:05:99 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 2 and the value is {"id":2,"itemName":"Iphone","price":949.49} and the partition is 2
17:05:99 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=2, itemName='Iphone', price=949.49}
17:05:99 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 1 and the value is {"id":1,"itemName":"LG TV","price":400.0} and the partition is 0
17:05:99 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=1, itemName='LG TV', price=400.0}
17:05:99 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 1 and the value is {"id":1,"itemName":"LG TV","price":400.0} and the partition is 0
17:05:99 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=1, itemName='LG TV', price=400.0}
17:05:99 [main] INFO  consumer.ItemConsumerApproach2 - Consumer Record key is 1 and the value is {"id":1,"itemName":"LG TV","price":400.0} and the partition is 0
17:05:99 [main] INFO  consumer.ItemConsumerApproach2 - Item : Item{id=1, itemName='LG TV', price=400.0}
17:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Failing OffsetCommit request since the consumer is not part of an active group
17:05:99 [main] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Synchronous auto-commit of offsets {items-2=OffsetAndMetadata{offset=3, leaderEpoch=6, metadata=''}, items-0=OffsetAndMetadata{offset=3, leaderEpoch=6, metadata=''}, items-1=OffsetAndMetadata{offset=0, leaderEpoch=null, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
17:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
17:05:99 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Lost previously assigned partitions items-2, items-0, items-1
17:05:99 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
17:05:99 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] (Re-)joining group
17:05:00 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Finished assignment for group at generation 340: {consumer-MessageConsumer2-1-fb9698d1-b998-447c-912d-984404ef529d=org.apache.kafka.clients.consumer.ConsumerPartitionAssignor$Assignment@63998bf4}
17:05:00 [main] INFO  o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Successfully joined group with generation 340
17:05:00 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Adding newly assigned partitions: items-2, items-0, items-1
17:05:00 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-2
17:05:00 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-0
17:05:00 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Found no committed offset for partition items-1
17:05:00 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-2 to offset 0.
17:05:00 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-0 to offset 0.
17:05:00 [main] INFO  o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-MessageConsumer2-1, groupId=MessageConsumer2] Resetting offset for partition items-1 to offset 0.
